<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 4 Compute vision models | Analysis Buffer</title>
<meta name="author" content="Patrick Li">
<meta name="description" content="4.1 Data There are 8860 observations in vi_survey. This includes all the attention checks and null lineups. If we need more data, the cost per observation is around 0.25 Australian Dollar. The...">
<meta name="generator" content="bookdown 0.30 with bs4_book()">
<meta property="og:title" content="Chapter 4 Compute vision models | Analysis Buffer">
<meta property="og:type" content="book">
<meta property="og:url" content="https://someurl.netlify.app/compute-vision-models.html">
<meta property="og:description" content="4.1 Data There are 8860 observations in vi_survey. This includes all the attention checks and null lineups. If we need more data, the cost per observation is around 0.25 Australian Dollar. The...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 4 Compute vision models | Analysis Buffer">
<meta name="twitter:description" content="4.1 Data There are 8860 observations in vi_survey. This includes all the attention checks and null lineups. If we need more data, the cost per observation is around 0.25 Australian Dollar. The...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.4.1/transition.js"></script><script src="libs/bs3compat-0.4.1/tabs.js"></script><script src="libs/bs3compat-0.4.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<link rel="stylesheet" href="bs4_style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Analysis Buffer</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Welcome</a></li>
<li><a class="" href="use-the-entire-dataset-to-perform-power-analysis.html"><span class="header-section-number">1</span> Use the entire dataset to perform power analysis</a></li>
<li><a class="" href="conventional-group-tests.html"><span class="header-section-number">2</span> Conventional group tests</a></li>
<li><a class="" href="group-test-reset-bp-and-sw.html"><span class="header-section-number">3</span> Group test (RESET, BP and SW)</a></li>
<li><a class="active" href="compute-vision-models.html"><span class="header-section-number">4</span> Compute vision models</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/TengMCing/analysis_buffer">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="compute-vision-models" class="section level1" number="4">
<h1>
<span class="header-section-number">4</span> Compute vision models<a class="anchor" aria-label="anchor" href="#compute-vision-models"><i class="fas fa-link"></i></a>
</h1>
<div id="data" class="section level2" number="4.1">
<h2>
<span class="header-section-number">4.1</span> Data<a class="anchor" aria-label="anchor" href="#data"><i class="fas fa-link"></i></a>
</h2>
<p>There are 8860 observations in <code>vi_survey</code>. This includes all the attention checks and null lineups. If we need more data, the cost per observation is around 0.25 Australian Dollar. The time needs for collecting the data is around 6 minutes per observation.</p>
</div>
<div id="types-of-model-grouped-by-types-of-training-data" class="section level2" number="4.2">
<h2>
<span class="header-section-number">4.2</span> Types of model grouped by types of training data<a class="anchor" aria-label="anchor" href="#types-of-model-grouped-by-types-of-training-data"><i class="fas fa-link"></i></a>
</h2>
<ul>
<li>Pure human training data</li>
<li>Simulated data + human data</li>
<li>Pure simulated data</li>
</ul>
<p>If we want a model that can mimic the behaviour of human, the direct way to train it is to use human data.</p>
<p>A larger training set can be formed if simulated data are also used.</p>
<p>Model trained with pure simulated data may not perform like humans. It is more like a conventional test that summarizes the information of residuals. Though it may not like a visual test conducted by human, it is still valuable.</p>
<div id="concerns" class="section level4" number="4.2.0.1">
<h4>
<span class="header-section-number">4.2.0.1</span> Concerns<a class="anchor" aria-label="anchor" href="#concerns"><i class="fas fa-link"></i></a>
</h4>
<p>Do we have sufficient data to train such a model? Some say we generally need &gt;1000 images for a label.</p>
<p>Can the model detect residual departures other than non-linearity and heteroskedasticity?
- It depends. If the model actually learns to select the most different residual plot, there is a chance of detecting other departures. But if the model only learns to detect the shapes we feed, then it probably will not be able to do it, unless other departures share similar characteristics of non-linearity and heteroskedasticity.</p>
<p>Can the model detect non-linearity and heteroskedasticity shapes other than what we design?</p>
</div>
</div>
<div id="potential-methods" class="section level2" number="4.3">
<h2>
<span class="header-section-number">4.3</span> Potential methods<a class="anchor" aria-label="anchor" href="#potential-methods"><i class="fas fa-link"></i></a>
</h2>
<p><a href="https://paperswithcode.com/" class="uri">https://paperswithcode.com/</a></p>
<div id="cores-of-computer-vision-models" class="section level3" number="4.3.1">
<h3>
<span class="header-section-number">4.3.1</span> Cores of computer vision models<a class="anchor" aria-label="anchor" href="#cores-of-computer-vision-models"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>CNN
<ul>
<li>Pooling layers</li>
<li>Convolutional layers</li>
</ul>
</li>
<li>Boltzmann family
<ul>
<li>Restricted Boltzmann Machines</li>
<li>Deep Belief Networks</li>
<li>Deep Boltzmann Machines</li>
</ul>
</li>
<li>Autoencoder
<ul>
<li>Denoising Autoencoders</li>
<li>Stacked Autoencoders</li>
</ul>
</li>
<li>Autoencoders
<ul>
<li>Distance between two data points in the embedding space (e.g.Â Faiss - Facebook)</li>
<li>Anomaly detection</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="group-test-reset-bp-and-sw.html"><span class="header-section-number">3</span> Group test (RESET, BP and SW)</a></div>
<div class="next"><a href="references.html">References</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#compute-vision-models"><span class="header-section-number">4</span> Compute vision models</a></li>
<li><a class="nav-link" href="#data"><span class="header-section-number">4.1</span> Data</a></li>
<li><a class="nav-link" href="#types-of-model-grouped-by-types-of-training-data"><span class="header-section-number">4.2</span> Types of model grouped by types of training data</a></li>
<li>
<a class="nav-link" href="#potential-methods"><span class="header-section-number">4.3</span> Potential methods</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#cores-of-computer-vision-models"><span class="header-section-number">4.3.1</span> Cores of computer vision models</a></li></ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/TengMCing/analysis_buffer/blob/master/01-entire-set.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/TengMCing/analysis_buffer/edit/master/01-entire-set.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Analysis Buffer</strong>" was written by Patrick Li. It was last built on 2023-05-10.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
