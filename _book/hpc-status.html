<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 7 HPC status | Analysis Buffer</title>
<meta name="author" content="Patrick Li">
<meta name="description" content="7.1 Workflow This section records the setup of the remote machine.  7.1.1 Project folder Create personal folder and clone the github repo. cd sk54 mkdir patrickli git clone...">
<meta name="generator" content="bookdown 0.30 with bs4_book()">
<meta property="og:title" content="Chapter 7 HPC status | Analysis Buffer">
<meta property="og:type" content="book">
<meta property="og:url" content="https://someurl.netlify.app/hpc-status.html">
<meta property="og:description" content="7.1 Workflow This section records the setup of the remote machine.  7.1.1 Project folder Create personal folder and clone the github repo. cd sk54 mkdir patrickli git clone...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 7 HPC status | Analysis Buffer">
<meta name="twitter:description" content="7.1 Workflow This section records the setup of the remote machine.  7.1.1 Project folder Create personal folder and clone the github repo. cd sk54 mkdir patrickli git clone...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.4.1/transition.js"></script><script src="libs/bs3compat-0.4.1/tabs.js"></script><script src="libs/bs3compat-0.4.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="bs4_style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Analysis Buffer</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Welcome</a></li>
<li><a class="" href="check-the-performance-of-conventional-tests-and-visual-tests-in-detecting-model-violations.html"><span class="header-section-number">1</span> Check the performance of conventional tests and visual tests in detecting model violations</a></li>
<li><a class="" href="conventional-combine-tests.html"><span class="header-section-number">2</span> Conventional combine tests</a></li>
<li><a class="" href="combined-tests-reset-bp-and-sw.html"><span class="header-section-number">3</span> Combined tests (RESET, BP and SW)</a></li>
<li><a class="" href="automatic-visual-inference-system.html"><span class="header-section-number">4</span> Automatic Visual Inference System</a></li>
<li><a class="" href="plan.html"><span class="header-section-number">5</span> Plan</a></li>
<li><a class="" href="hpc-m3-documentation.html"><span class="header-section-number">6</span> HPC (M3) Documentation</a></li>
<li><a class="active" href="hpc-status.html"><span class="header-section-number">7</span> HPC status</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/TengMCing/analysis_buffer">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="hpc-status" class="section level1" number="7">
<h1>
<span class="header-section-number">7</span> HPC status<a class="anchor" aria-label="anchor" href="#hpc-status"><i class="fas fa-link"></i></a>
</h1>
<div id="workflow" class="section level2" number="7.1">
<h2>
<span class="header-section-number">7.1</span> Workflow<a class="anchor" aria-label="anchor" href="#workflow"><i class="fas fa-link"></i></a>
</h2>
<p>This section records the setup of the remote machine.</p>
<div id="project-folder" class="section level3" number="7.1.1">
<h3>
<span class="header-section-number">7.1.1</span> Project folder<a class="anchor" aria-label="anchor" href="#project-folder"><i class="fas fa-link"></i></a>
</h3>
<p>Create personal folder and clone the github repo.</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb52-1"><a href="hpc-status.html#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> sk54</span>
<span id="cb52-2"><a href="hpc-status.html#cb52-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mkdir</span> patrickli</span>
<span id="cb52-3"><a href="hpc-status.html#cb52-3" aria-hidden="true" tabindex="-1"></a><span class="fu">git</span> clone https://github.com/TengMCing/automatic_visual_inference.git</span></code></pre></div>
</div>
<div id="tensorflow" class="section level3" number="7.1.2">
<h3>
<span class="header-section-number">7.1.2</span> <code>Tensorflow</code><a class="anchor" aria-label="anchor" href="#tensorflow"><i class="fas fa-link"></i></a>
</h3>
<p>Please make sure the terminal is fresh new and <strong>no modules</strong> have been loaded.</p>
<ol style="list-style-type: decimal">
<li>Install <code>miniconda</code>
</li>
</ol>
<p>We install the miniconda with the module <code>conda-install</code>.</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb53-1"><a href="hpc-status.html#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> ~</span>
<span id="cb53-2"><a href="hpc-status.html#cb53-2" aria-hidden="true" tabindex="-1"></a><span class="ex">module</span> load conda-install</span>
<span id="cb53-3"><a href="hpc-status.html#cb53-3" aria-hidden="true" tabindex="-1"></a><span class="ex">conda-install</span></span></code></pre></div>
<ol start="2" style="list-style-type: decimal">
<li>Init <code>conda</code>
</li>
</ol>
<p>Init the <code>conda</code> command. This will modify the <code>~/.bashrc</code> file.</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb54-1"><a href="hpc-status.html#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="ex">sk54_scratch/wlii0039/miniconda/bin/conda</span> init</span></code></pre></div>
<p>Source the <code>~/.bashrc</code> to load the <code>conda</code> command.</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb55-1"><a href="hpc-status.html#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="bu">source</span> ~/.bashrc</span></code></pre></div>
<ol start="3" style="list-style-type: decimal">
<li>Create <code>conda</code> environment</li>
</ol>
<p>We use the latest version of <code>Python</code>.</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb56-1"><a href="hpc-status.html#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> create <span class="at">--name</span> tf python=3.11</span></code></pre></div>
<p>Check if the GPU driver is available and the version is greater or equal to <code>450.80.82</code>. You need to run this step using a GPU node (e.g.Â M3 desktop with T4 GPU).</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb57-1"><a href="hpc-status.html#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="ex">nvidia-smi</span></span></code></pre></div>
<ol start="4" style="list-style-type: decimal">
<li>Install <code>cudatoolkit</code>
</li>
</ol>
<p>We first need to activate the conda environment. All the following steps require an activated environment.</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb58-1"><a href="hpc-status.html#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> activate tf</span></code></pre></div>
<p>You may notice that the system has several available <code>cuda</code> runtime API. We can check this by running the following command.</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb59-1"><a href="hpc-status.html#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="ex">module</span> avil cuda</span></code></pre></div>
<p>However, these <code>cuda</code> runtime APIs are not guaranteed to work with the desired <code>tensorflow</code> version as they may not have been tested by the <code>tensorflow</code> team (see <a href="https://www.tensorflow.org/install/source#linux" class="uri">https://www.tensorflow.org/install/source#linux</a> for tested build configuration). Ideally, we want to use our own runtime API.</p>
<p>This can be done by installing the desired version of <code>cudatoolkit</code> via <code>conda</code>. We specify the channel to be <code>conda-forge</code> since the package is available on that channel. And we want version <code>11.8.0</code> because <code>tensorflow-2.12</code> works nicely with this version.</p>
<div class="sourceCode" id="cb60"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb60-1"><a href="hpc-status.html#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> install <span class="at">-c</span> conda-forge cudatoolkit=11.8.0</span></code></pre></div>
<ol start="5" style="list-style-type: decimal">
<li>Install <code>cudnn</code>
</li>
</ol>
<p>Install <code>cudnn</code> via <code>pip</code> for training neural networks with GPUs. Version <code>8.6.0.163</code> has been tested by the <code>tensorflow</code> team so we use it.</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb61-1"><a href="hpc-status.html#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install nvidia-cudnn-cu11==8.6.0.163</span></code></pre></div>
<p>Since we are using our own <code>cuda</code> runtime API and <code>cudnn</code> API, we need to tell the program where to find the dynamic libraries. On unix system, this can be done by appending new paths to the environment variable <code>LD_LIBRARY_PATH</code>.</p>
<p>We can setup a startup script for the <code>tf</code> <code>conda</code> environment. Once <code>tf</code> is activated, the script will be executed. The script will be placed at <code>miniconda/conda/envs/tf/etc/conda/activate.d</code>.</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb62-1"><a href="hpc-status.html#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mkdir</span> <span class="at">-p</span> <span class="va">$CONDA_PREFIX</span>/etc/conda/activate.d</span>
<span id="cb62-2"><a href="hpc-status.html#cb62-2" aria-hidden="true" tabindex="-1"></a><span class="bu">echo</span> <span class="st">'CUDNN_PATH=$(dirname $(python -c "import nvidia.cudnn;print(nvidia.cudnn.__file__)"))'</span> <span class="op">&gt;&gt;</span> <span class="va">$CONDA_PREFIX</span>/etc/conda/activate.d/env_vars.sh</span>
<span id="cb62-3"><a href="hpc-status.html#cb62-3" aria-hidden="true" tabindex="-1"></a><span class="bu">echo</span> <span class="st">'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CONDA_PREFIX/lib/:$CUDNN_PATH/lib'</span> <span class="op">&gt;&gt;</span> <span class="va">$CONDA_PREFIX</span>/etc/conda/activate.d/env_vars.sh</span></code></pre></div>
<ol start="6" style="list-style-type: decimal">
<li>Install <code>tensorflow</code>
</li>
</ol>
<p>Before we install tensorflow, we need to update <code>pip</code> to the latest version.</p>
<div class="sourceCode" id="cb63"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb63-1"><a href="hpc-status.html#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install <span class="at">--upgrade</span> pip</span></code></pre></div>
<p>Install <code>tensorflow</code> and <code>pillow</code> (needed for image preprocessing).</p>
<div class="sourceCode" id="cb64"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb64-1"><a href="hpc-status.html#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install tensorflow==2.12.<span class="pp">*</span></span>
<span id="cb64-2"><a href="hpc-status.html#cb64-2" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install pillow</span></code></pre></div>
<ol start="7" style="list-style-type: decimal">
<li>Install <code>nvcc</code>
</li>
</ol>
<p>Usually, the <code>cudatoolkit</code> will come with a <code>cuda</code> compiler, but for some reasons, it does not ship with one to the appropriate location. This can be fixed by manually installing <code>nvcc</code> via <code>conda</code>.</p>
<div class="sourceCode" id="cb65"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb65-1"><a href="hpc-status.html#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> install <span class="at">-c</span> nvidia cuda-nvcc=11.3.58</span></code></pre></div>
<p>Again, we need to tell the program where to find the compiler.</p>
<div class="sourceCode" id="cb66"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb66-1"><a href="hpc-status.html#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="bu">printf</span> <span class="st">'export XLA_FLAGS=--xla_gpu_cuda_data_dir=$CONDA_PREFIX/lib/\n'</span> <span class="op">&gt;&gt;</span> <span class="va">$CONDA_PREFIX</span>/etc/conda/activate.d/env_vars.sh</span>
<span id="cb66-2"><a href="hpc-status.html#cb66-2" aria-hidden="true" tabindex="-1"></a><span class="bu">source</span> <span class="va">$CONDA_PREFIX</span>/etc/conda/activate.d/env_vars.sh</span>
<span id="cb66-3"><a href="hpc-status.html#cb66-3" aria-hidden="true" tabindex="-1"></a><span class="fu">mkdir</span> <span class="at">-p</span> <span class="va">$CONDA_PREFIX</span>/lib/nvvm/libdevice</span>
<span id="cb66-4"><a href="hpc-status.html#cb66-4" aria-hidden="true" tabindex="-1"></a><span class="fu">cp</span> <span class="va">$CONDA_PREFIX</span>/lib/libdevice.10.bc <span class="va">$CONDA_PREFIX</span>/lib/nvvm/libdevice/</span></code></pre></div>
<ol start="8" style="list-style-type: decimal">
<li>Verify the installation</li>
</ol>
<p>Check <code>python</code> version (3.11).</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb67-1"><a href="hpc-status.html#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="ex">python</span> <span class="at">--version</span></span></code></pre></div>
<p>Check <code>tensorflow</code>.</p>
<div class="sourceCode" id="cb68"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb68-1"><a href="hpc-status.html#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="ex">python</span> <span class="at">-c</span> <span class="st">"import tensorflow as tf; print(tf.reduce_sum(tf.random.normal([1000, 1000])))"</span></span></code></pre></div>
<p>Check if the GPU is detected.</p>
<div class="sourceCode" id="cb69"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb69-1"><a href="hpc-status.html#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="ex">python</span> <span class="at">-c</span> <span class="st">"import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"</span></span></code></pre></div>
<p>Use <code>python</code> to test the following code. Open another terminal, run the <code>nvidia-smi</code> command to monitor if <code>tensorflow</code> actually uses GPU.</p>
<div class="sourceCode" id="cb70"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb70-1"><a href="hpc-status.html#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb70-2"><a href="hpc-status.html#cb70-2" aria-hidden="true" tabindex="-1"></a>mnist <span class="op">=</span> tf.keras.datasets.mnist</span>
<span id="cb70-3"><a href="hpc-status.html#cb70-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-4"><a href="hpc-status.html#cb70-4" aria-hidden="true" tabindex="-1"></a>(x_train, y_train), (x_test, y_test) <span class="op">=</span> mnist.load_data()</span>
<span id="cb70-5"><a href="hpc-status.html#cb70-5" aria-hidden="true" tabindex="-1"></a>x_train, x_test <span class="op">=</span> x_train <span class="op">/</span> <span class="fl">255.0</span>, x_test <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb70-6"><a href="hpc-status.html#cb70-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-7"><a href="hpc-status.html#cb70-7" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> tf.keras.models.Sequential([</span>
<span id="cb70-8"><a href="hpc-status.html#cb70-8" aria-hidden="true" tabindex="-1"></a>  tf.keras.layers.Flatten(input_shape<span class="op">=</span>(<span class="dv">28</span>, <span class="dv">28</span>)),</span>
<span id="cb70-9"><a href="hpc-status.html#cb70-9" aria-hidden="true" tabindex="-1"></a>  tf.keras.layers.Dense(<span class="dv">128</span>, activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb70-10"><a href="hpc-status.html#cb70-10" aria-hidden="true" tabindex="-1"></a>  tf.keras.layers.Dropout(<span class="fl">0.2</span>),</span>
<span id="cb70-11"><a href="hpc-status.html#cb70-11" aria-hidden="true" tabindex="-1"></a>  tf.keras.layers.Dense(<span class="dv">10</span>)</span>
<span id="cb70-12"><a href="hpc-status.html#cb70-12" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb70-13"><a href="hpc-status.html#cb70-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-14"><a href="hpc-status.html#cb70-14" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">'adam'</span>,</span>
<span id="cb70-15"><a href="hpc-status.html#cb70-15" aria-hidden="true" tabindex="-1"></a>              loss<span class="op">=</span>tf.keras.losses.SparseCategoricalCrossentropy(from_logits<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb70-16"><a href="hpc-status.html#cb70-16" aria-hidden="true" tabindex="-1"></a>              metrics<span class="op">=</span>[<span class="st">'accuracy'</span>])</span>
<span id="cb70-17"><a href="hpc-status.html#cb70-17" aria-hidden="true" tabindex="-1"></a>              </span>
<span id="cb70-18"><a href="hpc-status.html#cb70-18" aria-hidden="true" tabindex="-1"></a>model.fit(x_train, y_train, epochs<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb70-19"><a href="hpc-status.html#cb70-19" aria-hidden="true" tabindex="-1"></a>model.evaluate(x_test,  y_test, verbose<span class="op">=</span><span class="dv">2</span>)</span></code></pre></div>
</div>
<div id="r" class="section level3" number="7.1.3">
<h3>
<span class="header-section-number">7.1.3</span> <code>R</code><a class="anchor" aria-label="anchor" href="#r"><i class="fas fa-link"></i></a>
</h3>
<p>We want to install some <code>R</code> libraries, but we are not allowed to write to the default library path. So we need to create a folder to store them.</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb71-1"><a href="hpc-status.html#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> sk54_scratch/wlii0039</span>
<span id="cb71-2"><a href="hpc-status.html#cb71-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mkdir</span> r_libs</span></code></pre></div>
<p>Specify the library location such that <code><a href="https://rdrr.io/r/base/libPaths.html">.libPaths()</a></code> will return the correct library path.</p>
<div class="sourceCode" id="cb72"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb72-1"><a href="hpc-status.html#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> ~</span>
<span id="cb72-2"><a href="hpc-status.html#cb72-2" aria-hidden="true" tabindex="-1"></a><span class="bu">echo</span> <span class="st">"R_LIBS=~/sk54_scratch/wlii0039/r_libs"</span> <span class="op">&gt;</span> .Renviron</span></code></pre></div>
<p>Since we may also want to use <code>tesnsorflow</code> in <code>R</code>, we need to specify some environment variables for <code>reticulate</code>.</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb73-1"><a href="hpc-status.html#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="bu">echo</span> <span class="st">"R_RETICULATE_CONDA=~/sk54_scratch/wlii0039/miniconda/bin/conda"</span> <span class="op">&gt;</span> .Renviron</span>
<span id="cb73-2"><a href="hpc-status.html#cb73-2" aria-hidden="true" tabindex="-1"></a><span class="bu">echo</span> <span class="st">"R_RETICULATE_PYTHON=~/sk54_scratch/wlii0039/miniconda/conda/envs/tf/bin/python"</span> <span class="op">&gt;</span> .Renviron</span></code></pre></div>
<p>Then, we can install our own libraries.</p>
<div class="sourceCode" id="cb74"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb74-1"><a href="hpc-status.html#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="ex">module</span> load R/4.0.5</span>
<span id="cb74-2"><a href="hpc-status.html#cb74-2" aria-hidden="true" tabindex="-1"></a><span class="ex">R</span></span></code></pre></div>
<div class="sourceCode" id="cb75"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">remotes</span><span class="fu">::</span><span class="fu"><a href="https://remotes.r-lib.org/reference/install_github.html">install_github</a></span><span class="op">(</span><span class="st">"TengMCing/bandicoot"</span><span class="op">)</span></span>
<span><span class="fu">remotes</span><span class="fu">::</span><span class="fu"><a href="https://remotes.r-lib.org/reference/install_github.html">install_github</a></span><span class="op">(</span><span class="st">"TengMCing/visage"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html">install.packages</a></span><span class="op">(</span><span class="st">"tidyverse"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html">install.packages</a></span><span class="op">(</span><span class="st">"tensorflow"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html">install.packages</a></span><span class="op">(</span><span class="st">"keras"</span><span class="op">)</span></span></code></pre></div>
</div>
</div>
<div id="experience" class="section level2" number="7.2">
<h2>
<span class="header-section-number">7.2</span> Experience<a class="anchor" aria-label="anchor" href="#experience"><i class="fas fa-link"></i></a>
</h2>
<ol style="list-style-type: decimal">
<li>The Massive desktop virtual machine is great, except for the key bindings if you are using Mac. The copy and paste key never work.</li>
<li>There are many different types of Massive desktop. P4 and single T4 are preferred since they have lower waiting time. Dual T4 and K80 are more powerful and both have 2 GPUs but it could be a waste if your program can not use multiple GPUs.</li>
<li>Massive desktop is also very important if you want to test the correctness of your code in an environment similar to the <code>sbatch</code> cluster. You can not modify your <code>sbatch</code> job, but you can test it on Massive desktop.</li>
<li>Libraries (dynamic or not) and software packages on Massive are often out-of-date. The latest version of R on Massive is 4.1.0-mkl which is a vesion of R linking to the Intel BLAS and LAPACK library. It is better not to use this version because it may give math result inconsistent to other machines. The R we are currently using is R 4.0.5 which is released on March 2021 missing some important feature updates such as the built-in pipe operator.</li>
<li>The out-of-date R is usually not a big deal. But the out-of-date system tools could make you mad. For
example, the important GPU driver <code>cuda</code> and <code>cudnn</code> provided by Massive are of version 10.1 and 7.6.5.32-cuda10 released on May 2019 and Nov 2019 respectively. Massive actually has newer version of <code>cuda</code> and <code>cudnn</code>, but I found they doesnât actually work with the âsupportedâ version of Python and tensorflow after reinstalling different configurations of my miniconda for 7 times. Further, some commonly used tools such as <code>conda</code> is also seriously out-of-date. Attempting to update it may also crash all of your <code>conda</code> environments.</li>
<li>The most important difference between the cluster and our local machine is the control of the available software and the software version. You can not easily install or update any important library on the cluster. This usually forces the user to install and use the out-of-date library on their own local machine such that the code can be tested locally.</li>
<li>The only working combination of Python, tensorflow, cuda and cudnn on Massive I found so far is Python 3.7, pandas 1.3, tensorflow 2.1.0, cuda 10.1 and cudnn 7.6.5.32-cuda10. I can not install Python 3.7 and tensorflow 2.1.0 on my local machine since Apple M1 doesnât support them (<a href="https://developer.apple.com/metal/tensorflow-plugin/" class="uri">https://developer.apple.com/metal/tensorflow-plugin/</a>). This means I have to (1) use the out-of-date keras APIs which is possibly deprecated on the version installed on my local machine (2) test them on Massive Desktop every time.</li>
<li>The VGG16 model spend around 30mins per epoch on thesingle T4 GPU. Training a model possibly needs around 50 epochs, so 25 hours.</li>
<li>The CPU on Massive is not very fast, sometimes it is even slower than M1. I have enabled multiprocessing on my data setup script, but it still takes around 3 hours to generate all the images.</li>
</ol>
</div>
<div id="status" class="section level2" number="7.3">
<h2>
<span class="header-section-number">7.3</span> Status<a class="anchor" aria-label="anchor" href="#status"><i class="fas fa-link"></i></a>
</h2>
<p>After fixing numerous issues, now I can successfully launch tensorflow training scripts on both the Massive desktop and the Massive cluster. The script can be written in R or Python. The R API is working correctly with tensorflow 2.1.0.</p>
<p>I have also setup the training data for the single residual plot model. The training data contains 141602 images, where 50% of them are null images and 50% of them are not null images. They are generated from three regression model with violations, namely polynomial model, heteroskedasticity model and non-normal model. Images of AR(1) model are also prepared but they are not mixed in the training data due to the difficulty of learning. The test data contains 14162 images.</p>
<div id="plans" class="section level3" number="7.3.1">
<h3>
<span class="header-section-number">7.3.1</span> Plans<a class="anchor" aria-label="anchor" href="#plans"><i class="fas fa-link"></i></a>
</h3>
<ol style="list-style-type: decimal">
<li>Train a VGG16 model via Massive desktop ensuring it works on the platform.</li>
<li>Train a VGG16 model via <code>sbatch</code> to see how long it takes.</li>
<li>Bring in keras-tuner to optimize the hyperparameters of VGG16. (use cross-validation?)</li>
<li>Try to use multiple GPU with <code>tf.distribute.MirroredStrategy()</code>. I also need to know how long it will take to schedule the job.</li>
<li>Try other architecture such as ResNet. Also use keras-tuner to optimize hyperparameters.</li>
</ol>
</div>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="hpc-m3-documentation.html"><span class="header-section-number">6</span> HPC (M3) Documentation</a></div>
<div class="next"><a href="references.html">References</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#hpc-status"><span class="header-section-number">7</span> HPC status</a></li>
<li>
<a class="nav-link" href="#workflow"><span class="header-section-number">7.1</span> Workflow</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#project-folder"><span class="header-section-number">7.1.1</span> Project folder</a></li>
<li><a class="nav-link" href="#tensorflow"><span class="header-section-number">7.1.2</span> Tensorflow</a></li>
<li><a class="nav-link" href="#r"><span class="header-section-number">7.1.3</span> R</a></li>
</ul>
</li>
<li><a class="nav-link" href="#experience"><span class="header-section-number">7.2</span> Experience</a></li>
<li>
<a class="nav-link" href="#status"><span class="header-section-number">7.3</span> Status</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#plans"><span class="header-section-number">7.3.1</span> Plans</a></li></ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/TengMCing/analysis_buffer/blob/master/06-HPC_status.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/TengMCing/analysis_buffer/edit/master/06-HPC_status.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Analysis Buffer</strong>" was written by Patrick Li. It was last built on 2023-06-14.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
