[{"path":"index.html","id":"welcome","chapter":"Welcome","heading":"Welcome","text":" place record temporary data analysis ideas.","code":""},{"path":"check-the-performance-of-conventional-tests-and-visual-tests-in-detecting-model-violations.html","id":"check-the-performance-of-conventional-tests-and-visual-tests-in-detecting-model-violations","chapter":"1 Check the performance of conventional tests and visual tests in detecting model violations","heading":"1 Check the performance of conventional tests and visual tests in detecting model violations","text":"compared performance conventional tests visual tests detecting non-linearity heteroskedasticity separately. chapter, try conduct similar analysis entire set data. Using conventional tests test residual departures designed may introduce Type III error. example, RESET test may correctly reject null hypothesis fail identify alternative hypothesis existence heteroskedasticity.","code":""},{"path":"check-the-performance-of-conventional-tests-and-visual-tests-in-detecting-model-violations.html","id":"load-libraries","chapter":"1 Check the performance of conventional tests and visual tests in detecting model violations","heading":"1.1 Load libraries","text":"","code":"\nlibrary(tidyverse)\nlibrary(visage)"},{"path":"check-the-performance-of-conventional-tests-and-visual-tests-in-detecting-model-violations.html","id":"load-data","chapter":"1 Check the performance of conventional tests and visual tests in detecting model violations","heading":"1.2 Load data","text":"","code":""},{"path":"check-the-performance-of-conventional-tests-and-visual-tests-in-detecting-model-violations.html","id":"visual-test-data","chapter":"1 Check the performance of conventional tests and visual tests in detecting model violations","heading":"1.2.1 Visual test data","text":"Data uniform distribution used similar paper.","code":"\nvisual_test_dat <- vi_survey %>%\n  filter(x_dist == \"uniform\", !attention_check, !null_lineup) %>%\n  select(unique_lineup_id, effect_size, type, p_value) %>%\n  group_by(unique_lineup_id) %>%\n  summarise(across(everything(), first))\nhead(visual_test_dat)\n#> # A tibble: 6 × 4\n#>   unique_lineup_id effect_size type                p_value\n#>   <chr>                  <dbl> <chr>                 <dbl>\n#> 1 heter_101             272.   heteroskedasticity 0.000269\n#> 2 heter_105               1.84 heteroskedasticity 0.824   \n#> 3 heter_110              20.6  heteroskedasticity 0.924   \n#> 4 heter_116              40.8  heteroskedasticity 0.0438  \n#> 5 heter_120               7.97 heteroskedasticity 0.0147  \n#> 6 heter_121              44.3  heteroskedasticity 0.0605"},{"path":"check-the-performance-of-conventional-tests-and-visual-tests-in-detecting-model-violations.html","id":"conventional-test-data","chapter":"1 Check the performance of conventional tests and visual tests in detecting model violations","heading":"1.2.2 Conventional test data","text":"simulation data borrowed paper.","code":"\npoly_conv_sim <- readRDS(\"data/poly_conventional_simulation.rds\")\nheter_conv_sim <- readRDS(\"data/heter_conventional_simulation.rds\")\n\n# Borrow effect size from the survey\npoly_conv_sim <- poly_conv_sim %>%\n  left_join(select(filter(vi_survey, type == \"polynomial\"), \n                   shape, e_sigma, n, x_dist, effect_size))\n\nheter_conv_sim <- heter_conv_sim %>%\n  left_join(select(filter(vi_survey, type == \"heteroskedasticity\"), \n                   a, b, n, x_dist, effect_size))\nconv_test_dat <- bind_rows(poly_conv_sim, heter_conv_sim) %>%\n  filter(x_dist == \"uniform\")\nhead(conv_test_dat)\n#> # A tibble: 6 × 19\n#>   shape e_sigma x_dist     n F_p_v…¹ RESET…² RESET…³ RESET…⁴\n#>   <dbl>   <dbl> <chr>  <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n#> 1     3       1 unifo…    50 5.24e-5   0.152 9.15e-4 8.29e-4\n#> 2     3       1 unifo…    50 5.24e-5   0.152 9.15e-4 8.29e-4\n#> 3     3       1 unifo…    50 5.24e-5   0.152 9.15e-4 8.29e-4\n#> 4     3       1 unifo…    50 5.24e-5   0.152 9.15e-4 8.29e-4\n#> 5     3       1 unifo…    50 5.24e-5   0.152 9.15e-4 8.29e-4\n#> 6     3       1 unifo…    50 5.24e-5   0.152 9.15e-4 8.29e-4\n#> # … with 11 more variables: RESET6_p_value <dbl>,\n#> #   RESET7_p_value <dbl>, RESET8_p_value <dbl>,\n#> #   RESET9_p_value <dbl>, RESET10_p_value <dbl>,\n#> #   BP_p_value <dbl>, SW_p_value <dbl>, boot_id <int>,\n#> #   effect_size <dbl>, a <dbl>, b <dbl>, and abbreviated\n#> #   variable names ¹​F_p_value, ²​RESET3_p_value,\n#> #   ³​RESET4_p_value, ⁴​RESET5_p_value"},{"path":"check-the-performance-of-conventional-tests-and-visual-tests-in-detecting-model-violations.html","id":"compute-glm-for-visual-test","chapter":"1 Check the performance of conventional tests and visual tests in detecting model violations","heading":"1.3 Compute GLM for visual test","text":"","code":""},{"path":"check-the-performance-of-conventional-tests-and-visual-tests-in-detecting-model-violations.html","id":"define-the-minimum-and-maximum-effect-size","chapter":"1 Check the performance of conventional tests and visual tests in detecting model violations","heading":"1.3.1 Define the minimum and maximum effect size","text":"","code":"\nmin_es <- vi_survey %>% \n  filter(!null_lineup, \n         !attention_check,\n         x_dist == \"uniform\") %>%\n  pull(effect_size) %>%\n  min()\n\nmax_es <- vi_survey %>% \n  filter(!null_lineup, \n         !attention_check,\n         x_dist == \"uniform\") %>%\n  pull(effect_size) %>%\n  max()\nc(log(min_es), log(max_es))\n#> [1] -1.450875  6.132414"},{"path":"check-the-performance-of-conventional-tests-and-visual-tests-in-detecting-model-violations.html","id":"fit-the-model","chapter":"1 Check the performance of conventional tests and visual tests in detecting model violations","heading":"1.3.2 Fit the model","text":"","code":"\nvisual_mod <- visual_test_dat %>%\n  mutate(offset0 = log(0.05/0.95)) %>%\n  mutate(reject = p_value <= 0.05) %>%\n  \n  # Slope-only model\n  glm(reject ~ effect_size - 1,\n      family = binomial(),\n      data = .,\n      offset = offset0)\nsummary(visual_mod)\n#> \n#> Call:\n#> glm(formula = reject ~ effect_size - 1, family = binomial(), \n#>     data = ., offset = offset0)\n#> \n#> Deviance Residuals: \n#>     Min       1Q   Median       3Q      Max  \n#> -3.0104  -0.4070  -0.3307   0.1368   2.2719  \n#> \n#> Coefficients:\n#>             Estimate Std. Error z value Pr(>|z|)    \n#> effect_size 0.098306   0.007402   13.28   <2e-16 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> (Dispersion parameter for binomial family taken to be 1)\n#> \n#>     Null deviance: 741.18  on 279  degrees of freedom\n#> Residual deviance: 195.65  on 278  degrees of freedom\n#> AIC: 197.65\n#> \n#> Number of Fisher Scoring iterations: 7"},{"path":"check-the-performance-of-conventional-tests-and-visual-tests-in-detecting-model-violations.html","id":"make-prediction-for-the-visual-model","chapter":"1 Check the performance of conventional tests and visual tests in detecting model violations","heading":"1.3.3 Make prediction for the visual model","text":"","code":"\nvisual_pred <- data.frame(effect_size = exp(seq(log(min_es), \n                                                log(max_es), \n                                                0.1))) %>%\n  mutate(power = predict(visual_mod, \n                         type = \"response\",\n                         newdata = data.frame(effect_size = effect_size,\n                                              offset0 = log(0.05/0.95)))) %>%\n  mutate(log_effect_size = log(effect_size))\nhead(visual_pred)\n#>   effect_size      power log_effect_size\n#> 1   0.2343650 0.05110579      -1.4508755\n#> 2   0.2590134 0.05122343      -1.3508755\n#> 3   0.2862541 0.05135373      -1.2508755\n#> 4   0.3163597 0.05149810      -1.1508755\n#> 5   0.3496315 0.05165810      -1.0508755\n#> 6   0.3864026 0.05183548      -0.9508755"},{"path":"check-the-performance-of-conventional-tests-and-visual-tests-in-detecting-model-violations.html","id":"make-bootstrap-prediction-for-the-visual-model","chapter":"1 Check the performance of conventional tests and visual tests in detecting model violations","heading":"1.3.4 Make bootstrap prediction for the visual model","text":"","code":"\nvisual_boot_pred <- map_dfr(1:500, function(boot_id) {\n  \n  boot_mod <- visual_test_dat %>%\n    mutate(offset0 = log(0.05/0.95)) %>%\n    mutate(reject = p_value <= 0.05) %>%\n    slice_sample(n = nrow(.), replace = TRUE) %>%\n    update(visual_mod, data = .)\n  \n  data.frame(effect_size = exp(seq(log(min_es), \n                                   log(max_es), \n                                   0.1))) %>%\n  mutate(power = predict(boot_mod, \n                         type = \"response\",\n                         newdata = data.frame(effect_size = effect_size,\n                                              offset0 = log(0.05/0.95)))) %>%\n  mutate(log_effect_size = log(effect_size)) %>%\n  mutate(boot_id = boot_id)\n})"},{"path":"check-the-performance-of-conventional-tests-and-visual-tests-in-detecting-model-violations.html","id":"compute-glm-for-conventional-tests","chapter":"1 Check the performance of conventional tests and visual tests in detecting model violations","heading":"1.4 Compute GLM for conventional tests","text":"","code":"\nconv_pred <- conv_test_dat %>%\n  select(-RESET3_p_value, -(RESET5_p_value:RESET10_p_value), -F_p_value) %>%\n  rename(RESET_p_value = RESET4_p_value) %>%\n  pivot_longer(RESET_p_value:SW_p_value) %>%\n  mutate(name = gsub(\"_p_value\", \" test\", name)) %>%\n  mutate(reject = value <= 0.05) %>%\n  select(effect_size, name, reject) %>%\n  mutate(offset0 = log(0.05/0.95)) %>%\n  nest(dat = c(effect_size, offset0, reject)) %>%\n  mutate(mod = map(dat, \n                   ~glm(reject ~ effect_size - 1, \n                        family = binomial(), \n                        data = .x,\n                        offset = offset0))) %>%\n  mutate(power = map(mod, function(mod) {\n    data.frame(effect_size = exp(seq(log(min_es),\n                                     log(max_es),\n                                     0.1)),\n               offset0 = log(0.05/0.95)) %>%\n      mutate(power = predict(mod, type = \"response\", newdata = .))\n  })) %>%\n  select(-dat, -mod) %>%\n  unnest(power) %>%\n  select(-offset0) %>%\n  mutate(log_effect_size = log(effect_size))"},{"path":"check-the-performance-of-conventional-tests-and-visual-tests-in-detecting-model-violations.html","id":"draw-the-plot","chapter":"1 Check the performance of conventional tests and visual tests in detecting model violations","heading":"1.5 Draw the plot","text":"","code":"\nggplot() +\n  geom_point(data = visual_test_dat,\n             aes(log(effect_size), as.numeric(p_value <= 0.05)),\n             alpha = 0.15) +\n  \n  geom_line(data = conv_pred,\n            aes(log_effect_size, power, col = name),\n            size = 1) +\n  \n  geom_line(data = visual_boot_pred,\n            aes(log_effect_size, power, col = \"visual test\", group = boot_id),\n            size = 1,\n            alpha = 0.01) +\n  \n  geom_line(data = visual_pred,\n            aes(log_effect_size, power, col = \"visual test\"), \n            size = 1) +\n  \n  theme_light() +\n  scale_color_manual(values = rev(rcartocolor::carto_pal(4, \"Vivid\"))) +\n  xlab(expression(log[e] (Effect_size))) +\n  ylab(\"Power\") +\n  labs(col = \"\", size = \"# lineups\")"},{"path":"conventional-combine-tests.html","id":"conventional-combine-tests","chapter":"2 Conventional combine tests","heading":"2 Conventional combine tests","text":"combine certain conventional tests together single test, .e. use extreme p-value final p-value (see),1 need adjust significance level individual test.Considering combined test consisting RESET test BP test, can estimate plot \\(p\\)-values based simulated data.","code":""},{"path":"conventional-combine-tests.html","id":"load-libraries-1","chapter":"2 Conventional combine tests","heading":"2.1 Load libraries","text":"","code":"\nlibrary(tidyverse)\nlibrary(visage)"},{"path":"conventional-combine-tests.html","id":"load-data-1","chapter":"2 Conventional combine tests","heading":"2.2 Load data","text":"","code":""},{"path":"conventional-combine-tests.html","id":"visual-test-data-1","chapter":"2 Conventional combine tests","heading":"2.2.1 Visual test data","text":"Data uniform distribution used similar paper.","code":"\nvisual_test_dat <- vi_survey %>%\n  filter(x_dist == \"uniform\", !attention_check, !null_lineup) %>%\n  select(unique_lineup_id, effect_size, type, p_value) %>%\n  group_by(unique_lineup_id) %>%\n  summarise(across(everything(), first))\nhead(visual_test_dat)\n#> # A tibble: 6 × 4\n#>   unique_lineup_id effect_size type                p_value\n#>   <chr>                  <dbl> <chr>                 <dbl>\n#> 1 heter_101             272.   heteroskedasticity 0.000269\n#> 2 heter_105               1.84 heteroskedasticity 0.824   \n#> 3 heter_110              20.6  heteroskedasticity 0.924   \n#> 4 heter_116              40.8  heteroskedasticity 0.0438  \n#> 5 heter_120               7.97 heteroskedasticity 0.0147  \n#> 6 heter_121              44.3  heteroskedasticity 0.0605"},{"path":"conventional-combine-tests.html","id":"conventional-test-data-1","chapter":"2 Conventional combine tests","heading":"2.2.2 Conventional test data","text":"simulation data borrowed paper.","code":"\npoly_conv_sim <- readRDS(\"data/poly_conventional_simulation.rds\")\nheter_conv_sim <- readRDS(\"data/heter_conventional_simulation.rds\")\n\n# Borrow effect size from the survey\npoly_conv_sim <- poly_conv_sim %>%\n  left_join(select(filter(vi_survey, type == \"polynomial\"), \n                   shape, e_sigma, n, x_dist, effect_size))\n\nheter_conv_sim <- heter_conv_sim %>%\n  left_join(select(filter(vi_survey, type == \"heteroskedasticity\"), \n                   a, b, n, x_dist, effect_size))\nconv_test_dat <- bind_rows(poly_conv_sim, heter_conv_sim) %>%\n  filter(x_dist == \"uniform\")\nhead(conv_test_dat)\n#> # A tibble: 6 × 19\n#>   shape e_sigma x_dist     n F_p_v…¹ RESET…² RESET…³ RESET…⁴\n#>   <dbl>   <dbl> <chr>  <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n#> 1     3       1 unifo…    50 5.24e-5   0.152 9.15e-4 8.29e-4\n#> 2     3       1 unifo…    50 5.24e-5   0.152 9.15e-4 8.29e-4\n#> 3     3       1 unifo…    50 5.24e-5   0.152 9.15e-4 8.29e-4\n#> 4     3       1 unifo…    50 5.24e-5   0.152 9.15e-4 8.29e-4\n#> 5     3       1 unifo…    50 5.24e-5   0.152 9.15e-4 8.29e-4\n#> 6     3       1 unifo…    50 5.24e-5   0.152 9.15e-4 8.29e-4\n#> # … with 11 more variables: RESET6_p_value <dbl>,\n#> #   RESET7_p_value <dbl>, RESET8_p_value <dbl>,\n#> #   RESET9_p_value <dbl>, RESET10_p_value <dbl>,\n#> #   BP_p_value <dbl>, SW_p_value <dbl>, boot_id <int>,\n#> #   effect_size <dbl>, a <dbl>, b <dbl>, and abbreviated\n#> #   variable names ¹​F_p_value, ²​RESET3_p_value,\n#> #   ³​RESET4_p_value, ⁴​RESET5_p_value"},{"path":"conventional-combine-tests.html","id":"compute-glm-for-visual-test-1","chapter":"2 Conventional combine tests","heading":"2.3 Compute GLM for visual test","text":"","code":""},{"path":"conventional-combine-tests.html","id":"define-the-minimum-and-maximum-effect-size-1","chapter":"2 Conventional combine tests","heading":"2.3.1 Define the minimum and maximum effect size","text":"","code":"\nmin_es <- vi_survey %>% \n  filter(!null_lineup, \n         !attention_check,\n         x_dist == \"uniform\") %>%\n  pull(effect_size) %>%\n  min()\n\nmax_es <- vi_survey %>% \n  filter(!null_lineup, \n         !attention_check,\n         x_dist == \"uniform\") %>%\n  pull(effect_size) %>%\n  max()\nc(log(min_es), log(max_es))\n#> [1] -1.450875  6.132414"},{"path":"conventional-combine-tests.html","id":"fit-the-model-1","chapter":"2 Conventional combine tests","heading":"2.3.2 Fit the model","text":"","code":"\nvisual_mod <- visual_test_dat %>%\n  mutate(offset0 = log(0.05/0.95)) %>%\n  mutate(reject = p_value <= 0.05) %>%\n  \n  # Slope-only model\n  glm(reject ~ effect_size - 1,\n      family = binomial(),\n      data = .,\n      offset = offset0)\nsummary(visual_mod)\n#> \n#> Call:\n#> glm(formula = reject ~ effect_size - 1, family = binomial(), \n#>     data = ., offset = offset0)\n#> \n#> Deviance Residuals: \n#>     Min       1Q   Median       3Q      Max  \n#> -3.0104  -0.4070  -0.3307   0.1368   2.2719  \n#> \n#> Coefficients:\n#>             Estimate Std. Error z value Pr(>|z|)    \n#> effect_size 0.098306   0.007402   13.28   <2e-16 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> (Dispersion parameter for binomial family taken to be 1)\n#> \n#>     Null deviance: 741.18  on 279  degrees of freedom\n#> Residual deviance: 195.65  on 278  degrees of freedom\n#> AIC: 197.65\n#> \n#> Number of Fisher Scoring iterations: 7"},{"path":"conventional-combine-tests.html","id":"make-prediction-for-the-visual-model-1","chapter":"2 Conventional combine tests","heading":"2.3.3 Make prediction for the visual model","text":"","code":"\nvisual_pred <- data.frame(effect_size = exp(seq(log(min_es), \n                                                log(max_es), \n                                                0.1))) %>%\n  mutate(power = predict(visual_mod, \n                         type = \"response\",\n                         newdata = data.frame(effect_size = effect_size,\n                                              offset0 = log(0.05/0.95)))) %>%\n  mutate(log_effect_size = log(effect_size))\nhead(visual_pred)\n#>   effect_size      power log_effect_size\n#> 1   0.2343650 0.05110579      -1.4508755\n#> 2   0.2590134 0.05122343      -1.3508755\n#> 3   0.2862541 0.05135373      -1.2508755\n#> 4   0.3163597 0.05149810      -1.1508755\n#> 5   0.3496315 0.05165810      -1.0508755\n#> 6   0.3864026 0.05183548      -0.9508755"},{"path":"conventional-combine-tests.html","id":"make-bootstrap-prediction-for-the-visual-model-1","chapter":"2 Conventional combine tests","heading":"2.3.4 Make bootstrap prediction for the visual model","text":"","code":"\nvisual_boot_pred <- map_dfr(1:500, function(boot_id) {\n  \n  boot_mod <- visual_test_dat %>%\n    mutate(offset0 = log(0.05/0.95)) %>%\n    mutate(reject = p_value <= 0.05) %>%\n    slice_sample(n = nrow(.), replace = TRUE) %>%\n    update(visual_mod, data = .)\n  \n  data.frame(effect_size = exp(seq(log(min_es), \n                                   log(max_es), \n                                   0.1))) %>%\n  mutate(power = predict(boot_mod, \n                         type = \"response\",\n                         newdata = data.frame(effect_size = effect_size,\n                                              offset0 = log(0.05/0.95)))) %>%\n  mutate(log_effect_size = log(effect_size)) %>%\n  mutate(boot_id = boot_id)\n})"},{"path":"conventional-combine-tests.html","id":"estimate-p-values-with-simulated-data","chapter":"2 Conventional combine tests","heading":"2.4 Estimate p-values with simulated data","text":"can pick rectangle area bottom left corner \\(P(\\text{RESET rejects } H_0 \\text{ BP rejects } H_0) = \\alpha\\). side length rectangle denoted \\(\\alpha^*\\).","code":"\nset.seed(10086)\n\nstand_dist <- function(x) (x - min(x))/max(x - min(x)) * 2 - 1\n\nconv_null_dat <- map_dfr(1:100000, function(i) {\n  \n  x_dist <- sample(c(\"uniform\", \n                     \"normal\", \n                     \"lognormal\", \n                     \"even_discrete\"), 1)\n  x <- switch(x_dist,\n              uniform = rand_uniform(-1, 1),\n              normal = {\n                raw_x <- rand_normal(sigma = 0.3)\n                closed_form(~stand_dist(raw_x))\n                },\n              lognormal = {\n                raw_x <- rand_lognormal(sigma = 0.6)\n                closed_form(~stand_dist(raw_x/3 - 1))\n                },\n              even_discrete = rand_uniform_d(k = 5, even = TRUE))\n        \n  mod <- poly_model(include_z = FALSE, x = x)\n  \n  n <- sample(c(50, 100, 300), 1)\n  \n  tmp_dat <- mod$gen(n)\n  \n  tibble(x_dist = x_dist,\n         n = n,\n         F_p_value = mod$test(tmp_dat)$p_value,\n         RESET_p_value = mod$test(tmp_dat, \n                                  test = \"RESET\", \n                                  power = 2:4, \n                                  power_type = \"fitted\")$p_value,\n         BP_p_value = HETER_MODEL$test(tmp_dat)$p_value,\n         SW_p_value = shapiro.test(tmp_dat$.resid)$p.value,\n         boot_id = i)\n})\nconv_null_dat %>%\n  ggplot() +\n  geom_density2d_filled(aes(RESET_p_value, BP_p_value)) +\n  scale_x_sqrt() +\n  scale_x_sqrt() +\n  xlab(\"RESET p-value\") +\n  ylab(\"BP p-value\")\nalpha_star <- map_dbl(seq(0.0001, 0.05, 0.0005), function(alpha_star) {\n  conv_null_dat %>%\n    filter(RESET_p_value <= alpha_star | BP_p_value <= alpha_star) %>%\n    nrow()/nrow(conv_null_dat)\n}) %>%\n  {seq(0.0001, 0.05, 0.0005)[which.min(abs(. - 0.05))]}\nalpha_star\n#> [1] 0.0271"},{"path":"conventional-combine-tests.html","id":"fit-glm","chapter":"2 Conventional combine tests","heading":"2.5 Fit GLM","text":"","code":"\nconv_test_group_dat <- conv_test_dat %>%\n  mutate(`Group test (RESET & BP)_p_value` = ifelse(RESET4_p_value <= alpha_star | BP_p_value <= alpha_star, 0, 1)) %>%\n  relocate(`Group test (RESET & BP)_p_value`, .after = SW_p_value)\nconv_pred_group <- conv_test_group_dat %>%\n  select(-RESET3_p_value, -(RESET5_p_value:RESET10_p_value), -F_p_value) %>%\n  rename(RESET_p_value = RESET4_p_value) %>%\n  pivot_longer(RESET_p_value:`Group test (RESET & BP)_p_value`) %>%\n  mutate(name = gsub(\"_p_value\", \" test\", name)) %>%\n  mutate(reject = value <= 0.05) %>%\n  select(effect_size, name, reject) %>%\n  mutate(offset0 = log(0.05/0.95)) %>%\n  nest(dat = c(effect_size, offset0, reject)) %>%\n  mutate(mod = map(dat, \n                   ~glm(reject ~ effect_size - 1, \n                        family = binomial(), \n                        data = .x,\n                        offset = offset0))) %>%\n  mutate(power = map(mod, function(mod) {\n    data.frame(effect_size = exp(seq(log(min_es),\n                                     log(max_es),\n                                     0.1)),\n               offset0 = log(0.05/0.95)) %>%\n      mutate(power = predict(mod, type = \"response\", newdata = .))\n  })) %>%\n  select(-dat, -mod) %>%\n  unnest(power) %>%\n  select(-offset0) %>%\n  mutate(log_effect_size = log(effect_size))"},{"path":"conventional-combine-tests.html","id":"draw-plot","chapter":"2 Conventional combine tests","heading":"2.6 Draw plot","text":"combined test higher power visual test case.","code":"\nggplot() +\n  geom_point(data = visual_test_dat,\n             aes(log(effect_size), as.numeric(p_value <= 0.05)),\n             alpha = 0.15) +\n  \n  geom_line(data = conv_pred_group,\n            aes(log_effect_size, power, col = name),\n            size = 1) +\n  \n  geom_line(data = visual_boot_pred,\n            aes(log_effect_size, power, col = \"visual test\", group = boot_id),\n            size = 1,\n            alpha = 0.01) +\n  \n  geom_line(data = visual_pred,\n            aes(log_effect_size, power, col = \"visual test\"), \n            size = 1) +\n  \n  theme_light() +\n  scale_color_manual(values = rev(rcartocolor::carto_pal(5, \"Vivid\"))) +\n  xlab(expression(log[e] (Effect_size))) +\n  ylab(\"Power\") +\n  labs(col = \"\", size = \"# lineups\")"},{"path":"combined-tests-reset-bp-and-sw.html","id":"combined-tests-reset-bp-and-sw","chapter":"3 Combined tests (RESET, BP and SW)","heading":"3 Combined tests (RESET, BP and SW)","text":"Let’s consider different combined tests consisting RESET test, BP test SW test.","code":"\nalpha_star2 <- map_dbl(seq(0.0001, 0.05, 0.0005), function(alpha_star) {\n  conv_null_dat %>%\n    filter(RESET_p_value <= alpha_star | SW_p_value <= alpha_star) %>%\n    nrow()/nrow(conv_null_dat)\n}) %>%\n  {seq(0.0001, 0.05, 0.0005)[which.min(abs(. - 0.05))]}\nalpha_star2\n#> [1] 0.0246\nalpha_star3 <- map_dbl(seq(0.0001, 0.05, 0.0005), function(alpha_star) {\n  conv_null_dat %>%\n    filter(BP_p_value <= alpha_star | SW_p_value <= alpha_star) %>%\n    nrow()/nrow(conv_null_dat)\n}) %>%\n  {seq(0.0001, 0.05, 0.0005)[which.min(abs(. - 0.05))]}\nalpha_star3\n#> [1] 0.0266\nalpha_star4 <- map_dbl(seq(0.0001, 0.05, 0.0005), function(alpha_star) {\n  conv_null_dat %>%\n    filter(RESET_p_value <= alpha_star | BP_p_value <= alpha_star | SW_p_value <= alpha_star) %>%\n    nrow()/nrow(conv_null_dat)\n}) %>%\n  {seq(0.0001, 0.05, 0.0005)[which.min(abs(. - 0.05))]}\nalpha_star4\n#> [1] 0.0176"},{"path":"combined-tests-reset-bp-and-sw.html","id":"fit-glm-1","chapter":"3 Combined tests (RESET, BP and SW)","heading":"3.1 Fit GLM","text":"","code":"\nconv_test_group_dat <- conv_test_dat %>%\n  mutate(`Group (RESET & BP)_p_value` = ifelse(RESET4_p_value <= alpha_star | BP_p_value <= alpha_star, 0, 1)) %>%\n  relocate(`Group (RESET & BP)_p_value`, .after = SW_p_value) %>%\n  \n  mutate(`Group (RESET & SW)_p_value` = ifelse(RESET4_p_value <= alpha_star2 | SW_p_value <= alpha_star2, 0, 1)) %>%\n  relocate(`Group (RESET & SW)_p_value`, .after = `Group (RESET & BP)_p_value`) %>%\n  \n  mutate(`Group (BP & SW)_p_value` = ifelse(BP_p_value <= alpha_star3 | SW_p_value <= alpha_star3, 0, 1)) %>%\n  relocate(`Group (BP & SW)_p_value`, .after = `Group (RESET & SW)_p_value`) %>%\n  \n  mutate(`Group (RESET & BP & SW)_p_value` = ifelse(RESET4_p_value <= alpha_star3 | BP_p_value <= alpha_star3 | SW_p_value <= alpha_star3, 0, 1)) %>%\n  relocate(`Group (RESET & BP & SW)_p_value`, .after = `Group (BP & SW)_p_value`)\nconv_pred_group <- conv_test_group_dat %>%\n  select(-RESET3_p_value, -(RESET5_p_value:RESET10_p_value), -F_p_value) %>%\n  rename(RESET_p_value = RESET4_p_value) %>%\n  pivot_longer(RESET_p_value:`Group (RESET & BP & SW)_p_value`) %>%\n  mutate(name = gsub(\"_p_value\", \" test\", name)) %>%\n  mutate(reject = value <= 0.05) %>%\n  select(effect_size, name, reject) %>%\n  mutate(offset0 = log(0.05/0.95)) %>%\n  nest(dat = c(effect_size, offset0, reject)) %>%\n  mutate(mod = map(dat, \n                   ~glm(reject ~ effect_size - 1, \n                        family = binomial(), \n                        data = .x,\n                        offset = offset0))) %>%\n  mutate(power = map(mod, function(mod) {\n    data.frame(effect_size = exp(seq(log(min_es),\n                                     log(max_es),\n                                     0.1)),\n               offset0 = log(0.05/0.95)) %>%\n      mutate(power = predict(mod, type = \"response\", newdata = .))\n  })) %>%\n  select(-dat, -mod) %>%\n  unnest(power) %>%\n  select(-offset0) %>%\n  mutate(log_effect_size = log(effect_size))\nconv_pred_group <- conv_pred_group %>%\n  mutate(name = factor(name, levels = c(\"Group (RESET & BP & SW) test\",\n                                        \"Group (RESET & BP) test\",\n                                        \"Visual test\",\n                                        \"Group (RESET & SW) test\",\n                                        \"Group (BP & SW) test\",\n                                        \"BP test\",\n                                        \"SW test\",\n                                        \"RESET test\")))"},{"path":"combined-tests-reset-bp-and-sw.html","id":"draw-plot-1","chapter":"3 Combined tests (RESET, BP and SW)","heading":"3.2 Draw plot","text":"sensitivity tests ordered follows:Group test (RESET & BP & SW)Group test (RESET & BP)Visual testGroup test (RESET & SW) testGroup test (BP & SW) testBP testSW testRESET test","code":"\nggplot() +\n  geom_point(data = visual_test_dat,\n             aes(log(effect_size), as.numeric(p_value <= 0.05)),\n             alpha = 0.15) +\n  \n  geom_line(data = conv_pred_group,\n            aes(log_effect_size, power, col = name),\n            size = 1) +\n  \n  geom_line(data = visual_boot_pred,\n            aes(log_effect_size, power, col = \"Visual test\", group = boot_id),\n            size = 1,\n            alpha = 0.01) +\n\n  geom_line(data = visual_pred,\n            aes(log_effect_size, power, col = \"Visual test\"),\n            size = 1) +\n  \n  theme_light() +\n  # scale_color_brewer(palette = \"Set3\") +\n  scale_color_manual(breaks = levels(conv_pred_group$name), \n                     values = rev(rcartocolor::carto_pal(8, \"Vivid\"))) +\n  xlab(expression(log[e] (Effect_size))) +\n  ylab(\"Power\") +\n  labs(col = \"\", size = \"# lineups\") +\n  theme(legend.position = \"bottom\")"},{"path":"automatic-visual-inference-system.html","id":"automatic-visual-inference-system","chapter":"4 Automatic Visual Inference System","heading":"4 Automatic Visual Inference System","text":"","code":"\nlibrary(tidyverse)\nlibrary(visage)"},{"path":"automatic-visual-inference-system.html","id":"objectives","chapter":"4 Automatic Visual Inference System","heading":"4.1 Objectives","text":"system’s objective described first second milestone reports evaluate lineups data plots, specifically residual plots, visual tests can conducted without involvement humans.conducting visual test, generally request participant select different plot lineup, cases, select multiple different plots lineup. Automating visual test means system needs ability complete task - select different plot lineup.Within context residual plots, different plot likely one look like good residual plot. may also contain visual patterns indicating model violations. Therefore, measuring different plot good residual plots also potential solution. words, system needs select one looks least like good residual plot. However, can anticipated system work types data plots, bar plots. accomplish task, need general-purpose (sense data plots) image comparison algorithm.","code":""},{"path":"automatic-visual-inference-system.html","id":"model-violations","chapter":"4 Automatic Visual Inference System","heading":"4.2 Model Violations","text":"giving p-values visual tests, system may also detect potential issues residual plots. model violations declared exposed system beforehand.two violations considered paper - non-linearity heteroskedasticity. simulate non-linearity Hermite polynomials simulate heteroskedasticity quadratic variance function. forms non-linearity, inverse exponential functions predictors. Heteroskedasticity also exhibit shapes “triangle” “butterfly”.Non-normality also mentioned paper. violation classical normal linear regression model assumption, important conducting hypothesis testing interval estimation. violation can simulated different commonly assumed distributions, like student’s t-distribution uniform distribution.Autocorrelation another worth-checking model violation. happens errors correlated different time periods. Regression analysis literature recommends use Durbin-Watson test. similar checking lag one sample autocorrelation coefficient. can simulate model violation AR(1) model.model violations commonly checked residual diagnostics. Instead simulating model violation separately, can also simulate mixed model violations, combination non-linearity non-normality.","code":""},{"path":"automatic-visual-inference-system.html","id":"inputs-and-outpus","chapter":"4 Automatic Visual Inference System","heading":"4.3 Inputs and outpus","text":"Grouped different kinds inputs outputs, can design system differently.consider input single residual plot, better aesthetic plot standardised. Users generally access raw residuals fitted values. may provide function help produce residual plot.Input: Single standard residual plotInput: Single standard residual plotOutput: probability plot begin rejected visual test.Output: probability plot begin rejected visual test.Input: Single standard residual plotInput: Single standard residual plotOutput: probability plot exhibiting residual departures.Output: probability plot exhibiting residual departures.Raw-Input: Residuals fitted valuesRaw-Input: Residuals fitted valuesInput: Single standard residual plotInput: Single standard residual plotOutput: probability plot exhibiting residual departures.Output: probability plot exhibiting residual departures.mentioned , system may also provide type model violations. can usually done multiclass classifier.Raw-Input: Residuals fitted valuesInput: Single standard residual plotOutput: probability plot exhibiting departure (multiclass).Additionally, raw numerical data may used additional information help make accurate predictions.Raw-Input: Residuals fitted valuesRaw-Input: Residuals fitted valuesInput: Standard residual plot & residualsInput: Standard residual plot & residualsOutput: probability plot exhibiting residual departures.Output: probability plot exhibiting residual departures.Raw-Input: Residuals fitted valuesRaw-Input: Residuals fitted valuesInput: Standard residual plot & residualsInput: Standard residual plot & residualsOutput: probability plot exhibiting departure (multiclass).Output: probability plot exhibiting departure (multiclass).like follow lineup protocol, input system lineup residual plots. can ask system perform task humans, select different plot(s).Input: Multiple residual plots (lineup)Input: Multiple residual plots (lineup)Output: different plot.Output: different plot.Input: Multiple residual plots (lineup)Input: Multiple residual plots (lineup)Output: different plots.Output: different plots., unlike humans, computer vision models can possibly produce ranking residual plots lineup. ranking, novel inference method can developed.Input: Multiple residual plots (lineup)Output: Ranking (different plot)","code":""},{"path":"automatic-visual-inference-system.html","id":"data","chapter":"4 Automatic Visual Inference System","heading":"4.4 Data","text":"terms training computer vision model(s) embedded system. need consider data available moment. 8860 lineup evaluations collected experiment. means least thousand images per class (null plot ).need data, cost per observation around 0.25 Australian Dollars. time needs collecting data around 6 minutes per observation.also let model learn characteristics null plots exposing simulated null plots .potential sources data.Pure human dataSimulated data + human dataPure simulated dataIf want model can mimic behaviour humans, direct way train use human data. However, larger training set can formed simulated data also used. Models trained pure simulated data may perform like humans. like conventional test summarizes information residuals. Though may like visual test conducted humans, still valuable.","code":""},{"path":"automatic-visual-inference-system.html","id":"architectures","chapter":"4 Automatic Visual Inference System","heading":"4.5 Architectures","text":"terms model architectures, first need consider availability source code. Due time constraint, possibility need borrow CNN model structures existing model, VGG16 ResNet.different kinds CNN model architectures can considered:Traditional image classifier\nVGG16, VGG19, etc.\nAvailable Keras Applications\nMature APIs\naccepts single image time, want use multiple images input, need design new model.\nVGG16, VGG19, etc.Available Keras ApplicationsMature APIsBut accepts single image time, want use multiple images input, need design new model.Generative adversarial network\nBased idea autoencoders\nReproduce null plots\nDenoise null plots\nreproduced target plot different target plot, likely plot exhibiting residual departures.\nBased idea autoencodersReproduce null plotsDenoise null plotsIf reproduced target plot different target plot, likely plot exhibiting residual departures.","code":""},{"path":"automatic-visual-inference-system.html","id":"concerns","chapter":"4 Automatic Visual Inference System","heading":"4.6 Concerns","text":"sufficient data train model? say generally need >1000 images label.Can model detect residual departures non-linearity heteroskedasticity?\n- depends. model actually learns select different residual plot, chance detecting departures. model learns detect shapes feed, probably able , unless departures share similar characteristics non-linearity heteroskedasticity.Can model detect non-linearity heteroskedasticity shapes design?Can model applied data plots?","code":""},{"path":"plan.html","id":"plan","chapter":"5 Plan","heading":"5 Plan","text":"","code":""},{"path":"plan.html","id":"summary-of-the-current-progress","chapter":"5 Plan","heading":"5.1 Summary of the current progress","text":"identified several potential methods constructing system. However, numerous crucial questions currently remain unanswered. instance, uncertain whether system can effectively detect residual departures manner similar humans. address , necessary proceed training computer vision model conduct experiments test hypothesis.essential emphasize importance accurate training extensive testing ensure reliability effectiveness system. preparing wide range scenarios collecting comprehensive data, can gain valuable insights capabilities limitations. Additionally, ongoing evaluation refinement computer vision model necessary address potential shortcomings.","code":""},{"path":"plan.html","id":"plan-for-the-next-step","chapter":"5 Plan","heading":"5.2 Plan for the next step","text":"facilitate better organization adherence project timeline, detailed plan outlined :","code":""},{"path":"plan.html","id":"define-the-objectives","chapter":"5 Plan","heading":"5.2.1 Define the Objectives","text":"Clearly establish goals objectives system, including specific requirements detecting residual departures. can found previous chapter.","code":""},{"path":"plan.html","id":"data-prepration","chapter":"5 Plan","heading":"5.2.2 Data Prepration","text":"Prepare diverse representative dataset encompasses various types departures corresponding human observations. Types departures like consider :Non-linearity\nHermite polynomials\nHermite polynomialsHeteroskedasticity\nVariance error quadratic function regressor\nVariance error quadratic function regressorNon-normality\nNon-normal error\nNon-normal errorAutocorrelation\nAR1 included predictor\nAR1 included predictorThis cover common model violations classical normal linear regression model. particular focus residual vs. fitted values plot, autocorrelation generally can detected type plot.like prepare least 10,000 images per type violation.","code":""},{"path":"plan.html","id":"model-training","chapter":"5 Plan","heading":"5.2.3 Model Training","text":"Develop implement training pipeline incorporates state---art computer vision techniques. Train model using collected dataset, ensuring balance performance computational efficiency.consider basic model first, traditional CNN classifier deciding whether residual plot null plot. Additionally, need train multiclass classifier providing useful information fixing model violation., advanced models GAN can considered follow lineup protocol closely. traditional classifier GAN models can discussed paper. curious performance.","code":""},{"path":"plan.html","id":"testing-and-evaluation","chapter":"5 Plan","heading":"5.2.4 Testing and Evaluation","text":"Conduct rigorous testing applying trained model range real-world scenarios comparing performance human observations. Measure accuracy, precision, recall, relevant metrics assess model’s effectiveness.need come standard metrics evaluating model performance.","code":""},{"path":"plan.html","id":"iterative-refinement","chapter":"5 Plan","heading":"5.2.5 Iterative refinement","text":"Based evaluation results, identify areas model may fall short refine training process accordingly. Continuously iterate model architecture, hyperparameters, training techniques improve performance.","code":""},{"path":"plan.html","id":"extension","chapter":"5 Plan","heading":"5.3 Extension","text":"Try different type residual diagnostic plots.Try different aesthetics styles.","code":""},{"path":"hpc-m3-documentation.html","id":"hpc-m3-documentation","chapter":"6 HPC (M3) Documentation","heading":"6 HPC (M3) Documentation","text":"chapter documenting use HPC terms folder structure, model setup, tasks submission, etc.","code":""},{"path":"hpc-m3-documentation.html","id":"help-and-support","chapter":"6 HPC (M3) Documentation","heading":"6.1 Help and Support","text":"Encounter network issues? Check system stauts https://monasheresearch.statuspage.io/.Send email help@massive.org.au withCommandsSimple reproducible exampleFull path slurm script input filesSoftware usedError messages","code":""},{"path":"hpc-m3-documentation.html","id":"nodes-for-job-submission","chapter":"6 HPC (M3) Documentation","heading":"6.2 Nodes for Job Submission","text":"K80T4P100V100A40DGX1","code":""},{"path":"hpc-m3-documentation.html","id":"remote-desktop","chapter":"6 HPC (M3) Documentation","heading":"6.3 Remote Desktop","text":"P4: 60T4: 32Dual T4: 16K80: 26A40: 16","code":""},{"path":"hpc-m3-documentation.html","id":"connection-methods","chapter":"6 HPC (M3) Documentation","heading":"6.4 Connection Methods","text":"","code":""},{"path":"hpc-m3-documentation.html","id":"ssh","chapter":"6 HPC (M3) Documentation","heading":"6.4.1 ssh","text":"","code":"ssh -l username m3.massive.org.au"},{"path":"hpc-m3-documentation.html","id":"x11-port-forwarding","chapter":"6 HPC (M3) Documentation","heading":"6.4.2 X11 port forwarding","text":"Trusted X11 forwardingEnables X11 forwarding","code":"ssh -l username m3.massive.org.au -Yssh -l username m3.massive.org.au -X"},{"path":"hpc-m3-documentation.html","id":"remote-desktop-1","chapter":"6 HPC (M3) Documentation","heading":"6.5 Remote Desktop","text":"Strudel Web (http://desktop.massive.org.au/)Strudel2 (https://beta.desktop.cvl.org.au/login)\nUse P4 single-T4. single GPU, easier used.\nUse P4 single-T4. single GPU, easier used.Great setting environment interactively.","code":""},{"path":"hpc-m3-documentation.html","id":"change-the-size-of-the-desktop","chapter":"6 HPC (M3) Documentation","heading":"6.5.1 Change the Size of the Desktop","text":"Use xrandr -s \"1920 * 1080\" desktop terminal.Use TurboVNC (ctl-cmd-shift-o?), “Connection Option”","code":""},{"path":"hpc-m3-documentation.html","id":"connection-speed","chapter":"6 HPC (M3) Documentation","heading":"6.5.2 Connection Speed","text":"Use “WAN” options “Encoding method” TurboVNC","code":""},{"path":"hpc-m3-documentation.html","id":"others","chapter":"6 HPC (M3) Documentation","heading":"6.5.3 Others","text":"remote machine may copy paste keys different local machine.\n- can copy paste Mac keyboard!","code":""},{"path":"hpc-m3-documentation.html","id":"jupyter-lab","chapter":"6 HPC (M3) Documentation","heading":"6.5.4 Jupyter Lab","text":"Disable pop-blockerInstall user site package pip install --user pkg_nameOr !pip install --user pkg_nameOr create conda env/venvpip list installed","code":""},{"path":"hpc-m3-documentation.html","id":"login-node-vs.-compute-node","chapter":"6 HPC (M3) Documentation","heading":"6.5.5 Login Node VS. Compute Node","text":"Login node editing scripts submitting jobs.\n- can also install packages node.","code":""},{"path":"hpc-m3-documentation.html","id":"use-miniconda","chapter":"6 HPC (M3) Documentation","heading":"6.5.6 Use Miniconda","text":"https://docs.massive.org.au/M3/software/pythonandconda/python-miniconda.html#python-miniconda","code":"module load conda-install\n\n# Install miniconda to default space (/scratch/sk54/username/miniconda)\nconda-install\n\n# Init conda (modify .bashrc)\n/scratch/sk54/wlii0039/miniconda/bin/conda init\n\n# Create env (Note that there is an environment called jupyterlab that can be used)\nconda create --name myenv -f myenv.yml\n\nconda activate myenvconda install pkg_name=ver_num\n\nconda update pkg_name=ver_num"},{"path":"hpc-m3-documentation.html","id":"add-new-env-to-jupyterlab","chapter":"6 HPC (M3) Documentation","heading":"6.5.6.1 Add New Env to JupyterLab","text":"","code":"add-strudel2-conda /path/to/miniconda/ newJupyterEnv"},{"path":"hpc-m3-documentation.html","id":"vs-code-connection","chapter":"6 HPC (M3) Documentation","heading":"6.5.7 VS Code Connection","text":"https://docs.massive.org.au/M3/connecting/strudel2/connecting--vscode.html","code":""},{"path":"hpc-m3-documentation.html","id":"useful-commands","chapter":"6 HPC (M3) Documentation","heading":"6.6 Useful commands","text":"user_infoshow_jobshow_clusternvidia-smi (cuda cudnn module loaded)","code":""},{"path":"hpc-m3-documentation.html","id":"file-systems","chapter":"6 HPC (M3) Documentation","heading":"6.7 File systems","text":"Two symbolic links:\n- ~/project_name: backed daily\n- ~/project_name_scratch: backed ","code":""},{"path":"hpc-m3-documentation.html","id":"space","chapter":"6 HPC (M3) Documentation","heading":"6.7.1 Space","text":"Home (10GB)\nConfiguration files\nPersonal settings\nConfiguration filesPersonal settingsProject (50GB? 500GB?)\nInput data\nJob scripts\nOutput data\nCreate subdirectory (e.g. “~/project/patrickli”)\nInput dataJob scriptsOutput dataCreate subdirectory (e.g. “~/project/patrickli”)Scratch (3TB)\nIntermediate data\nData actively processed\nIntermediate dataData actively processed","code":""},{"path":"hpc-m3-documentation.html","id":"filezilla","chapter":"6 HPC (M3) Documentation","heading":"6.8 FileZilla","text":"Site-ManagerNew Site (SFTP)Host: m3-dtn.massive.org.auLogon Type: Ask PasswordUser: my_usernameEnter password","code":""},{"path":"hpc-m3-documentation.html","id":"modules","chapter":"6 HPC (M3) Documentation","heading":"6.9 Modules","text":"","code":"module avail mod_name\n\n# To use a module\nmodule load mod_name\n\n# Loaded module\nmodule list\n\n# Learn more\nmodule show mod_name\n\nmodule unload mod_name\n\n# Kill all loaded modules\nmodule purge"},{"path":"hpc-m3-documentation.html","id":"jobs","chapter":"6 HPC (M3) Documentation","heading":"6.10 Jobs","text":"https://slurm.schedmd.com/show_cluster","code":""},{"path":"hpc-m3-documentation.html","id":"slurm-accounts","chapter":"6 HPC (M3) Documentation","heading":"6.10.1 Slurm Accounts","text":"sacctmgr show user $USER format=User,DefaultAccount","code":""},{"path":"hpc-m3-documentation.html","id":"job-submission","chapter":"6 HPC (M3) Documentation","heading":"6.10.2 Job Submission","text":"https://docs.massive.org.au/M3/slurm/simple-batch-jobs.htmlsbatch jobs.scriptscancel job_id","code":""},{"path":"hpc-status.html","id":"hpc-status","chapter":"7 HPC status","heading":"7 HPC status","text":"","code":""},{"path":"hpc-status.html","id":"workflow","chapter":"7 HPC status","heading":"7.1 Workflow","text":"section records setup remote machine.","code":"# Create personal folder and clone the github repo\ncd sk54\nmkdir patrickli\ngit clone https://github.com/TengMCing/automatic_visual_inference.git\n\n# Install tensorflow and init conda\ncd ~\nmodule load conda-install\nconda-install\nsk54_scratch/wlii0039/miniconda/bin/conda init\nconda create --name tf2-gpu\n\n# Please strictly follow these two steps\n# This is the only working tf setup\nconda install python==3.7 pandas==1.3\npip install tensorflow==2.1.0\n\n# Check if the GPU is recognized\n# Please use exactly these two libraries\nmodule load cuda/10.1\nmodule load cudnn/7.6.5.32-cuda10\npython -c \"import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\"\n\n# Create a folder to install our own R packages\ncd sk54_scratch/wlii0039\nmkdir r_libs\n\n# Specify the library location such that `.libPaths()` will return the\n# correct library path\ncd ~\necho \"R_LIBS=~/sk54_scratch/wlii0039/r_libs\" > .Renviron\n\n# Specify the `reticulate` environment variable\necho \"R_RETICULATE_CONDA=~/sk54_scratch/wlii0039/miniconda/bin/conda\" > .Renviron\necho \"R_RETICULATE_PYTHON=~/sk54_scratch/wlii0039/miniconda/conda/envs/tf2-gpu/bin/python\" > .Renviron\n\n# Install our R packages to `r_libs`\nmodule load R/4.0.5\nR\nremotes::install_github(\"TengMCing/bandicoot\")\nremotes::install_github(\"TengMCing/visage\")\ninstall.packages(\"tidyverse\")\ninstall.packages(\"tensorflow\")\ninstall.packages(\"keras\")"},{"path":"hpc-status.html","id":"experience","chapter":"7 HPC status","heading":"7.2 Experience","text":"Massive desktop virtual machine great, except key bindings using Mac. copy paste key never work.many different types Massive desktop. P4 single T4 preferred since lower waiting time. Dual T4 K80 powerful 2 GPUs waste program can use multiple GPUs.Massive desktop also important want test correctness code environment similar sbatch cluster. can modify sbatch job, can test Massive desktop.Libraries (dynamic ) software packages Massive often --date. latest version R Massive 4.1.0-mkl vesion R linking Intel BLAS LAPACK library. better use version may give math result inconsistent machines. R currently using R 4.0.5 released March 2021 missing important feature updates built-pipe operator.--date R usually big deal. --date system tools make mad. \nexample, important GPU driver cuda cudnn provided Massive version 10.1 7.6.5.32-cuda10 released May 2019 Nov 2019 respectively. Massive actually newer version cuda cudnn, found doesn’t actually work “supported” version Python tensorflow reinstalling different configurations miniconda 7 times. , commonly used tools conda also seriously --date. Attempting update may also crash conda environments.important difference cluster local machine control available software software version. can easily install update important library cluster. usually forces user install use --date library local machine code can tested locally.working combination Python, tensorflow, cuda cudnn Massive found far Python 3.7, pandas 1.3, tensorflow 2.1.0, cuda 10.1 cudnn 7.6.5.32-cuda10. can install Python 3.7 tensorflow 2.1.0 local machine since Apple M1 doesn’t support (https://developer.apple.com/metal/tensorflow-plugin/). means (1) use --date keras APIs possibly deprecated version installed local machine (2) test Massive Desktop every time.VGG16 model spend around 30mins per epoch thesingle T4 GPU. Training model possibly needs around 50 epochs, 25 hours.CPU Massive fast, sometimes even slower M1. enabled multiprocessing data setup script, still takes around 3 hours generate images.","code":""},{"path":"hpc-status.html","id":"status","chapter":"7 HPC status","heading":"7.3 Status","text":"fixing numerous issues, now can successfully launch tensorflow training scripts Massive desktop ","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
