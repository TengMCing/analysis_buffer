[{"path":"index.html","id":"welcome","chapter":"Welcome","heading":"Welcome","text":" place record temporary data analysis ideas.","code":""},{"path":"check-the-performance-of-conventional-tests-and-visual-tests-in-detecting-model-violations.html","id":"check-the-performance-of-conventional-tests-and-visual-tests-in-detecting-model-violations","chapter":"1 Check the performance of conventional tests and visual tests in detecting model violations","heading":"1 Check the performance of conventional tests and visual tests in detecting model violations","text":"compared performance conventional tests visual tests detecting non-linearity heteroskedasticity separately. chapter, try conduct similar analysis entire set data. Using conventional tests test residual departures designed may introduce Type III error. example, RESET test may correctly reject null hypothesis fail identify alternative hypothesis existence heteroskedasticity.","code":""},{"path":"check-the-performance-of-conventional-tests-and-visual-tests-in-detecting-model-violations.html","id":"load-libraries","chapter":"1 Check the performance of conventional tests and visual tests in detecting model violations","heading":"1.1 Load libraries","text":"","code":"\nlibrary(tidyverse)\nlibrary(visage)"},{"path":"check-the-performance-of-conventional-tests-and-visual-tests-in-detecting-model-violations.html","id":"load-data","chapter":"1 Check the performance of conventional tests and visual tests in detecting model violations","heading":"1.2 Load data","text":"","code":""},{"path":"check-the-performance-of-conventional-tests-and-visual-tests-in-detecting-model-violations.html","id":"visual-test-data","chapter":"1 Check the performance of conventional tests and visual tests in detecting model violations","heading":"1.2.1 Visual test data","text":"Data uniform distribution used similar paper.","code":"\nvisual_test_dat <- vi_survey %>%\n  filter(x_dist == \"uniform\", !attention_check, !null_lineup) %>%\n  select(unique_lineup_id, effect_size, type, p_value) %>%\n  group_by(unique_lineup_id) %>%\n  summarise(across(everything(), first))\nhead(visual_test_dat)\n#> # A tibble: 6 × 4\n#>   unique_lineup_id effect_size type                p_value\n#>   <chr>                  <dbl> <chr>                 <dbl>\n#> 1 heter_101             272.   heteroskedasticity 0.000269\n#> 2 heter_105               1.84 heteroskedasticity 0.824   \n#> 3 heter_110              20.6  heteroskedasticity 0.924   \n#> 4 heter_116              40.8  heteroskedasticity 0.0438  \n#> 5 heter_120               7.97 heteroskedasticity 0.0147  \n#> 6 heter_121              44.3  heteroskedasticity 0.0605"},{"path":"check-the-performance-of-conventional-tests-and-visual-tests-in-detecting-model-violations.html","id":"conventional-test-data","chapter":"1 Check the performance of conventional tests and visual tests in detecting model violations","heading":"1.2.2 Conventional test data","text":"simulation data borrowed paper.","code":"\npoly_conv_sim <- readRDS(\"data/poly_conventional_simulation.rds\")\nheter_conv_sim <- readRDS(\"data/heter_conventional_simulation.rds\")\n\n# Borrow effect size from the survey\npoly_conv_sim <- poly_conv_sim %>%\n  left_join(select(filter(vi_survey, type == \"polynomial\"), \n                   shape, e_sigma, n, x_dist, effect_size))\n\nheter_conv_sim <- heter_conv_sim %>%\n  left_join(select(filter(vi_survey, type == \"heteroskedasticity\"), \n                   a, b, n, x_dist, effect_size))\nconv_test_dat <- bind_rows(poly_conv_sim, heter_conv_sim) %>%\n  filter(x_dist == \"uniform\")\nhead(conv_test_dat)\n#> # A tibble: 6 × 19\n#>   shape e_sigma x_dist     n F_p_v…¹ RESET…² RESET…³ RESET…⁴\n#>   <dbl>   <dbl> <chr>  <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n#> 1     3       1 unifo…    50 5.24e-5   0.152 9.15e-4 8.29e-4\n#> 2     3       1 unifo…    50 5.24e-5   0.152 9.15e-4 8.29e-4\n#> 3     3       1 unifo…    50 5.24e-5   0.152 9.15e-4 8.29e-4\n#> 4     3       1 unifo…    50 5.24e-5   0.152 9.15e-4 8.29e-4\n#> 5     3       1 unifo…    50 5.24e-5   0.152 9.15e-4 8.29e-4\n#> 6     3       1 unifo…    50 5.24e-5   0.152 9.15e-4 8.29e-4\n#> # … with 11 more variables: RESET6_p_value <dbl>,\n#> #   RESET7_p_value <dbl>, RESET8_p_value <dbl>,\n#> #   RESET9_p_value <dbl>, RESET10_p_value <dbl>,\n#> #   BP_p_value <dbl>, SW_p_value <dbl>, boot_id <int>,\n#> #   effect_size <dbl>, a <dbl>, b <dbl>, and abbreviated\n#> #   variable names ¹​F_p_value, ²​RESET3_p_value,\n#> #   ³​RESET4_p_value, ⁴​RESET5_p_value"},{"path":"check-the-performance-of-conventional-tests-and-visual-tests-in-detecting-model-violations.html","id":"compute-glm-for-visual-test","chapter":"1 Check the performance of conventional tests and visual tests in detecting model violations","heading":"1.3 Compute GLM for visual test","text":"","code":""},{"path":"check-the-performance-of-conventional-tests-and-visual-tests-in-detecting-model-violations.html","id":"define-the-minimum-and-maximum-effect-size","chapter":"1 Check the performance of conventional tests and visual tests in detecting model violations","heading":"1.3.1 Define the minimum and maximum effect size","text":"","code":"\nmin_es <- vi_survey %>% \n  filter(!null_lineup, \n         !attention_check,\n         x_dist == \"uniform\") %>%\n  pull(effect_size) %>%\n  min()\n\nmax_es <- vi_survey %>% \n  filter(!null_lineup, \n         !attention_check,\n         x_dist == \"uniform\") %>%\n  pull(effect_size) %>%\n  max()\nc(log(min_es), log(max_es))\n#> [1] -1.450875  6.132414"},{"path":"check-the-performance-of-conventional-tests-and-visual-tests-in-detecting-model-violations.html","id":"fit-the-model","chapter":"1 Check the performance of conventional tests and visual tests in detecting model violations","heading":"1.3.2 Fit the model","text":"","code":"\nvisual_mod <- visual_test_dat %>%\n  mutate(offset0 = log(0.05/0.95)) %>%\n  mutate(reject = p_value <= 0.05) %>%\n  \n  # Slope-only model\n  glm(reject ~ effect_size - 1,\n      family = binomial(),\n      data = .,\n      offset = offset0)\nsummary(visual_mod)\n#> \n#> Call:\n#> glm(formula = reject ~ effect_size - 1, family = binomial(), \n#>     data = ., offset = offset0)\n#> \n#> Deviance Residuals: \n#>     Min       1Q   Median       3Q      Max  \n#> -3.0104  -0.4070  -0.3307   0.1368   2.2719  \n#> \n#> Coefficients:\n#>             Estimate Std. Error z value Pr(>|z|)    \n#> effect_size 0.098306   0.007402   13.28   <2e-16 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> (Dispersion parameter for binomial family taken to be 1)\n#> \n#>     Null deviance: 741.18  on 279  degrees of freedom\n#> Residual deviance: 195.65  on 278  degrees of freedom\n#> AIC: 197.65\n#> \n#> Number of Fisher Scoring iterations: 7"},{"path":"check-the-performance-of-conventional-tests-and-visual-tests-in-detecting-model-violations.html","id":"make-prediction-for-the-visual-model","chapter":"1 Check the performance of conventional tests and visual tests in detecting model violations","heading":"1.3.3 Make prediction for the visual model","text":"","code":"\nvisual_pred <- data.frame(effect_size = exp(seq(log(min_es), \n                                                log(max_es), \n                                                0.1))) %>%\n  mutate(power = predict(visual_mod, \n                         type = \"response\",\n                         newdata = data.frame(effect_size = effect_size,\n                                              offset0 = log(0.05/0.95)))) %>%\n  mutate(log_effect_size = log(effect_size))\nhead(visual_pred)\n#>   effect_size      power log_effect_size\n#> 1   0.2343650 0.05110579      -1.4508755\n#> 2   0.2590134 0.05122343      -1.3508755\n#> 3   0.2862541 0.05135373      -1.2508755\n#> 4   0.3163597 0.05149810      -1.1508755\n#> 5   0.3496315 0.05165810      -1.0508755\n#> 6   0.3864026 0.05183548      -0.9508755"},{"path":"check-the-performance-of-conventional-tests-and-visual-tests-in-detecting-model-violations.html","id":"make-bootstrap-prediction-for-the-visual-model","chapter":"1 Check the performance of conventional tests and visual tests in detecting model violations","heading":"1.3.4 Make bootstrap prediction for the visual model","text":"","code":"\nvisual_boot_pred <- map_dfr(1:500, function(boot_id) {\n  \n  boot_mod <- visual_test_dat %>%\n    mutate(offset0 = log(0.05/0.95)) %>%\n    mutate(reject = p_value <= 0.05) %>%\n    slice_sample(n = nrow(.), replace = TRUE) %>%\n    update(visual_mod, data = .)\n  \n  data.frame(effect_size = exp(seq(log(min_es), \n                                   log(max_es), \n                                   0.1))) %>%\n  mutate(power = predict(boot_mod, \n                         type = \"response\",\n                         newdata = data.frame(effect_size = effect_size,\n                                              offset0 = log(0.05/0.95)))) %>%\n  mutate(log_effect_size = log(effect_size)) %>%\n  mutate(boot_id = boot_id)\n})"},{"path":"check-the-performance-of-conventional-tests-and-visual-tests-in-detecting-model-violations.html","id":"compute-glm-for-conventional-tests","chapter":"1 Check the performance of conventional tests and visual tests in detecting model violations","heading":"1.4 Compute GLM for conventional tests","text":"","code":"\nconv_pred <- conv_test_dat %>%\n  select(-RESET3_p_value, -(RESET5_p_value:RESET10_p_value), -F_p_value) %>%\n  rename(RESET_p_value = RESET4_p_value) %>%\n  pivot_longer(RESET_p_value:SW_p_value) %>%\n  mutate(name = gsub(\"_p_value\", \" test\", name)) %>%\n  mutate(reject = value <= 0.05) %>%\n  select(effect_size, name, reject) %>%\n  mutate(offset0 = log(0.05/0.95)) %>%\n  nest(dat = c(effect_size, offset0, reject)) %>%\n  mutate(mod = map(dat, \n                   ~glm(reject ~ effect_size - 1, \n                        family = binomial(), \n                        data = .x,\n                        offset = offset0))) %>%\n  mutate(power = map(mod, function(mod) {\n    data.frame(effect_size = exp(seq(log(min_es),\n                                     log(max_es),\n                                     0.1)),\n               offset0 = log(0.05/0.95)) %>%\n      mutate(power = predict(mod, type = \"response\", newdata = .))\n  })) %>%\n  select(-dat, -mod) %>%\n  unnest(power) %>%\n  select(-offset0) %>%\n  mutate(log_effect_size = log(effect_size))"},{"path":"check-the-performance-of-conventional-tests-and-visual-tests-in-detecting-model-violations.html","id":"draw-the-plot","chapter":"1 Check the performance of conventional tests and visual tests in detecting model violations","heading":"1.5 Draw the plot","text":"","code":"\nggplot() +\n  geom_point(data = visual_test_dat,\n             aes(log(effect_size), as.numeric(p_value <= 0.05)),\n             alpha = 0.15) +\n  \n  geom_line(data = conv_pred,\n            aes(log_effect_size, power, col = name),\n            size = 1) +\n  \n  geom_line(data = visual_boot_pred,\n            aes(log_effect_size, power, col = \"visual test\", group = boot_id),\n            size = 1,\n            alpha = 0.01) +\n  \n  geom_line(data = visual_pred,\n            aes(log_effect_size, power, col = \"visual test\"), \n            size = 1) +\n  \n  theme_light() +\n  scale_color_manual(values = rev(rcartocolor::carto_pal(4, \"Vivid\"))) +\n  xlab(expression(log[e] (Effect_size))) +\n  ylab(\"Power\") +\n  labs(col = \"\", size = \"# lineups\")"},{"path":"conventional-combine-tests.html","id":"conventional-combine-tests","chapter":"2 Conventional combine tests","heading":"2 Conventional combine tests","text":"combine certain conventional tests together single test, .e. use extreme p-value final p-value (see),1 need adjust significance level individual test.Considering combined test consisting RESET test BP test, can estimate plot \\(p\\)-values based simulated data.","code":""},{"path":"conventional-combine-tests.html","id":"load-libraries-1","chapter":"2 Conventional combine tests","heading":"2.1 Load libraries","text":"","code":"\nlibrary(tidyverse)\nlibrary(visage)"},{"path":"conventional-combine-tests.html","id":"load-data-1","chapter":"2 Conventional combine tests","heading":"2.2 Load data","text":"","code":""},{"path":"conventional-combine-tests.html","id":"visual-test-data-1","chapter":"2 Conventional combine tests","heading":"2.2.1 Visual test data","text":"Data uniform distribution used similar paper.","code":"\nvisual_test_dat <- vi_survey %>%\n  filter(x_dist == \"uniform\", !attention_check, !null_lineup) %>%\n  select(unique_lineup_id, effect_size, type, p_value) %>%\n  group_by(unique_lineup_id) %>%\n  summarise(across(everything(), first))\nhead(visual_test_dat)\n#> # A tibble: 6 × 4\n#>   unique_lineup_id effect_size type                p_value\n#>   <chr>                  <dbl> <chr>                 <dbl>\n#> 1 heter_101             272.   heteroskedasticity 0.000269\n#> 2 heter_105               1.84 heteroskedasticity 0.824   \n#> 3 heter_110              20.6  heteroskedasticity 0.924   \n#> 4 heter_116              40.8  heteroskedasticity 0.0438  \n#> 5 heter_120               7.97 heteroskedasticity 0.0147  \n#> 6 heter_121              44.3  heteroskedasticity 0.0605"},{"path":"conventional-combine-tests.html","id":"conventional-test-data-1","chapter":"2 Conventional combine tests","heading":"2.2.2 Conventional test data","text":"simulation data borrowed paper.","code":"\npoly_conv_sim <- readRDS(\"data/poly_conventional_simulation.rds\")\nheter_conv_sim <- readRDS(\"data/heter_conventional_simulation.rds\")\n\n# Borrow effect size from the survey\npoly_conv_sim <- poly_conv_sim %>%\n  left_join(select(filter(vi_survey, type == \"polynomial\"), \n                   shape, e_sigma, n, x_dist, effect_size))\n\nheter_conv_sim <- heter_conv_sim %>%\n  left_join(select(filter(vi_survey, type == \"heteroskedasticity\"), \n                   a, b, n, x_dist, effect_size))\nconv_test_dat <- bind_rows(poly_conv_sim, heter_conv_sim) %>%\n  filter(x_dist == \"uniform\")\nhead(conv_test_dat)\n#> # A tibble: 6 × 19\n#>   shape e_sigma x_dist     n F_p_v…¹ RESET…² RESET…³ RESET…⁴\n#>   <dbl>   <dbl> <chr>  <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n#> 1     3       1 unifo…    50 5.24e-5   0.152 9.15e-4 8.29e-4\n#> 2     3       1 unifo…    50 5.24e-5   0.152 9.15e-4 8.29e-4\n#> 3     3       1 unifo…    50 5.24e-5   0.152 9.15e-4 8.29e-4\n#> 4     3       1 unifo…    50 5.24e-5   0.152 9.15e-4 8.29e-4\n#> 5     3       1 unifo…    50 5.24e-5   0.152 9.15e-4 8.29e-4\n#> 6     3       1 unifo…    50 5.24e-5   0.152 9.15e-4 8.29e-4\n#> # … with 11 more variables: RESET6_p_value <dbl>,\n#> #   RESET7_p_value <dbl>, RESET8_p_value <dbl>,\n#> #   RESET9_p_value <dbl>, RESET10_p_value <dbl>,\n#> #   BP_p_value <dbl>, SW_p_value <dbl>, boot_id <int>,\n#> #   effect_size <dbl>, a <dbl>, b <dbl>, and abbreviated\n#> #   variable names ¹​F_p_value, ²​RESET3_p_value,\n#> #   ³​RESET4_p_value, ⁴​RESET5_p_value"},{"path":"conventional-combine-tests.html","id":"compute-glm-for-visual-test-1","chapter":"2 Conventional combine tests","heading":"2.3 Compute GLM for visual test","text":"","code":""},{"path":"conventional-combine-tests.html","id":"define-the-minimum-and-maximum-effect-size-1","chapter":"2 Conventional combine tests","heading":"2.3.1 Define the minimum and maximum effect size","text":"","code":"\nmin_es <- vi_survey %>% \n  filter(!null_lineup, \n         !attention_check,\n         x_dist == \"uniform\") %>%\n  pull(effect_size) %>%\n  min()\n\nmax_es <- vi_survey %>% \n  filter(!null_lineup, \n         !attention_check,\n         x_dist == \"uniform\") %>%\n  pull(effect_size) %>%\n  max()\nc(log(min_es), log(max_es))\n#> [1] -1.450875  6.132414"},{"path":"conventional-combine-tests.html","id":"fit-the-model-1","chapter":"2 Conventional combine tests","heading":"2.3.2 Fit the model","text":"","code":"\nvisual_mod <- visual_test_dat %>%\n  mutate(offset0 = log(0.05/0.95)) %>%\n  mutate(reject = p_value <= 0.05) %>%\n  \n  # Slope-only model\n  glm(reject ~ effect_size - 1,\n      family = binomial(),\n      data = .,\n      offset = offset0)\nsummary(visual_mod)\n#> \n#> Call:\n#> glm(formula = reject ~ effect_size - 1, family = binomial(), \n#>     data = ., offset = offset0)\n#> \n#> Deviance Residuals: \n#>     Min       1Q   Median       3Q      Max  \n#> -3.0104  -0.4070  -0.3307   0.1368   2.2719  \n#> \n#> Coefficients:\n#>             Estimate Std. Error z value Pr(>|z|)    \n#> effect_size 0.098306   0.007402   13.28   <2e-16 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> (Dispersion parameter for binomial family taken to be 1)\n#> \n#>     Null deviance: 741.18  on 279  degrees of freedom\n#> Residual deviance: 195.65  on 278  degrees of freedom\n#> AIC: 197.65\n#> \n#> Number of Fisher Scoring iterations: 7"},{"path":"conventional-combine-tests.html","id":"make-prediction-for-the-visual-model-1","chapter":"2 Conventional combine tests","heading":"2.3.3 Make prediction for the visual model","text":"","code":"\nvisual_pred <- data.frame(effect_size = exp(seq(log(min_es), \n                                                log(max_es), \n                                                0.1))) %>%\n  mutate(power = predict(visual_mod, \n                         type = \"response\",\n                         newdata = data.frame(effect_size = effect_size,\n                                              offset0 = log(0.05/0.95)))) %>%\n  mutate(log_effect_size = log(effect_size))\nhead(visual_pred)\n#>   effect_size      power log_effect_size\n#> 1   0.2343650 0.05110579      -1.4508755\n#> 2   0.2590134 0.05122343      -1.3508755\n#> 3   0.2862541 0.05135373      -1.2508755\n#> 4   0.3163597 0.05149810      -1.1508755\n#> 5   0.3496315 0.05165810      -1.0508755\n#> 6   0.3864026 0.05183548      -0.9508755"},{"path":"conventional-combine-tests.html","id":"make-bootstrap-prediction-for-the-visual-model-1","chapter":"2 Conventional combine tests","heading":"2.3.4 Make bootstrap prediction for the visual model","text":"","code":"\nvisual_boot_pred <- map_dfr(1:500, function(boot_id) {\n  \n  boot_mod <- visual_test_dat %>%\n    mutate(offset0 = log(0.05/0.95)) %>%\n    mutate(reject = p_value <= 0.05) %>%\n    slice_sample(n = nrow(.), replace = TRUE) %>%\n    update(visual_mod, data = .)\n  \n  data.frame(effect_size = exp(seq(log(min_es), \n                                   log(max_es), \n                                   0.1))) %>%\n  mutate(power = predict(boot_mod, \n                         type = \"response\",\n                         newdata = data.frame(effect_size = effect_size,\n                                              offset0 = log(0.05/0.95)))) %>%\n  mutate(log_effect_size = log(effect_size)) %>%\n  mutate(boot_id = boot_id)\n})"},{"path":"conventional-combine-tests.html","id":"estimate-p-values-with-simulated-data","chapter":"2 Conventional combine tests","heading":"2.4 Estimate p-values with simulated data","text":"can pick rectangle area bottom left corner \\(P(\\text{RESET rejects } H_0 \\text{ BP rejects } H_0) = \\alpha\\). side length rectangle denoted \\(\\alpha^*\\).","code":"\nset.seed(10086)\n\nstand_dist <- function(x) (x - min(x))/max(x - min(x)) * 2 - 1\n\nconv_null_dat <- map_dfr(1:100000, function(i) {\n  \n  x_dist <- sample(c(\"uniform\", \n                     \"normal\", \n                     \"lognormal\", \n                     \"even_discrete\"), 1)\n  x <- switch(x_dist,\n              uniform = rand_uniform(-1, 1),\n              normal = {\n                raw_x <- rand_normal(sigma = 0.3)\n                closed_form(~stand_dist(raw_x))\n                },\n              lognormal = {\n                raw_x <- rand_lognormal(sigma = 0.6)\n                closed_form(~stand_dist(raw_x/3 - 1))\n                },\n              even_discrete = rand_uniform_d(k = 5, even = TRUE))\n        \n  mod <- poly_model(include_z = FALSE, x = x)\n  \n  n <- sample(c(50, 100, 300), 1)\n  \n  tmp_dat <- mod$gen(n)\n  \n  tibble(x_dist = x_dist,\n         n = n,\n         F_p_value = mod$test(tmp_dat)$p_value,\n         RESET_p_value = mod$test(tmp_dat, \n                                  test = \"RESET\", \n                                  power = 2:4, \n                                  power_type = \"fitted\")$p_value,\n         BP_p_value = HETER_MODEL$test(tmp_dat)$p_value,\n         SW_p_value = shapiro.test(tmp_dat$.resid)$p.value,\n         boot_id = i)\n})\nconv_null_dat %>%\n  ggplot() +\n  geom_density2d_filled(aes(RESET_p_value, BP_p_value)) +\n  scale_x_sqrt() +\n  scale_x_sqrt() +\n  xlab(\"RESET p-value\") +\n  ylab(\"BP p-value\")\nalpha_star <- map_dbl(seq(0.0001, 0.05, 0.0005), function(alpha_star) {\n  conv_null_dat %>%\n    filter(RESET_p_value <= alpha_star | BP_p_value <= alpha_star) %>%\n    nrow()/nrow(conv_null_dat)\n}) %>%\n  {seq(0.0001, 0.05, 0.0005)[which.min(abs(. - 0.05))]}\nalpha_star\n#> [1] 0.0271"},{"path":"conventional-combine-tests.html","id":"fit-glm","chapter":"2 Conventional combine tests","heading":"2.5 Fit GLM","text":"","code":"\nconv_test_group_dat <- conv_test_dat %>%\n  mutate(`Group test (RESET & BP)_p_value` = ifelse(RESET4_p_value <= alpha_star | BP_p_value <= alpha_star, 0, 1)) %>%\n  relocate(`Group test (RESET & BP)_p_value`, .after = SW_p_value)\nconv_pred_group <- conv_test_group_dat %>%\n  select(-RESET3_p_value, -(RESET5_p_value:RESET10_p_value), -F_p_value) %>%\n  rename(RESET_p_value = RESET4_p_value) %>%\n  pivot_longer(RESET_p_value:`Group test (RESET & BP)_p_value`) %>%\n  mutate(name = gsub(\"_p_value\", \" test\", name)) %>%\n  mutate(reject = value <= 0.05) %>%\n  select(effect_size, name, reject) %>%\n  mutate(offset0 = log(0.05/0.95)) %>%\n  nest(dat = c(effect_size, offset0, reject)) %>%\n  mutate(mod = map(dat, \n                   ~glm(reject ~ effect_size - 1, \n                        family = binomial(), \n                        data = .x,\n                        offset = offset0))) %>%\n  mutate(power = map(mod, function(mod) {\n    data.frame(effect_size = exp(seq(log(min_es),\n                                     log(max_es),\n                                     0.1)),\n               offset0 = log(0.05/0.95)) %>%\n      mutate(power = predict(mod, type = \"response\", newdata = .))\n  })) %>%\n  select(-dat, -mod) %>%\n  unnest(power) %>%\n  select(-offset0) %>%\n  mutate(log_effect_size = log(effect_size))"},{"path":"conventional-combine-tests.html","id":"draw-plot","chapter":"2 Conventional combine tests","heading":"2.6 Draw plot","text":"combined test higher power visual test case.","code":"\nggplot() +\n  geom_point(data = visual_test_dat,\n             aes(log(effect_size), as.numeric(p_value <= 0.05)),\n             alpha = 0.15) +\n  \n  geom_line(data = conv_pred_group,\n            aes(log_effect_size, power, col = name),\n            size = 1) +\n  \n  geom_line(data = visual_boot_pred,\n            aes(log_effect_size, power, col = \"visual test\", group = boot_id),\n            size = 1,\n            alpha = 0.01) +\n  \n  geom_line(data = visual_pred,\n            aes(log_effect_size, power, col = \"visual test\"), \n            size = 1) +\n  \n  theme_light() +\n  scale_color_manual(values = rev(rcartocolor::carto_pal(5, \"Vivid\"))) +\n  xlab(expression(log[e] (Effect_size))) +\n  ylab(\"Power\") +\n  labs(col = \"\", size = \"# lineups\")"},{"path":"combined-tests-reset-bp-and-sw.html","id":"combined-tests-reset-bp-and-sw","chapter":"3 Combined tests (RESET, BP and SW)","heading":"3 Combined tests (RESET, BP and SW)","text":"Let’s consider different combined tests consisting RESET test, BP test SW test.","code":"\nalpha_star2 <- map_dbl(seq(0.0001, 0.05, 0.0005), function(alpha_star) {\n  conv_null_dat %>%\n    filter(RESET_p_value <= alpha_star | SW_p_value <= alpha_star) %>%\n    nrow()/nrow(conv_null_dat)\n}) %>%\n  {seq(0.0001, 0.05, 0.0005)[which.min(abs(. - 0.05))]}\nalpha_star2\n#> [1] 0.0246\nalpha_star3 <- map_dbl(seq(0.0001, 0.05, 0.0005), function(alpha_star) {\n  conv_null_dat %>%\n    filter(BP_p_value <= alpha_star | SW_p_value <= alpha_star) %>%\n    nrow()/nrow(conv_null_dat)\n}) %>%\n  {seq(0.0001, 0.05, 0.0005)[which.min(abs(. - 0.05))]}\nalpha_star3\n#> [1] 0.0266\nalpha_star4 <- map_dbl(seq(0.0001, 0.05, 0.0005), function(alpha_star) {\n  conv_null_dat %>%\n    filter(RESET_p_value <= alpha_star | BP_p_value <= alpha_star | SW_p_value <= alpha_star) %>%\n    nrow()/nrow(conv_null_dat)\n}) %>%\n  {seq(0.0001, 0.05, 0.0005)[which.min(abs(. - 0.05))]}\nalpha_star4\n#> [1] 0.0176"},{"path":"combined-tests-reset-bp-and-sw.html","id":"fit-glm-1","chapter":"3 Combined tests (RESET, BP and SW)","heading":"3.1 Fit GLM","text":"","code":"\nconv_test_group_dat <- conv_test_dat %>%\n  mutate(`Group (RESET & BP)_p_value` = ifelse(RESET4_p_value <= alpha_star | BP_p_value <= alpha_star, 0, 1)) %>%\n  relocate(`Group (RESET & BP)_p_value`, .after = SW_p_value) %>%\n  \n  mutate(`Group (RESET & SW)_p_value` = ifelse(RESET4_p_value <= alpha_star2 | SW_p_value <= alpha_star2, 0, 1)) %>%\n  relocate(`Group (RESET & SW)_p_value`, .after = `Group (RESET & BP)_p_value`) %>%\n  \n  mutate(`Group (BP & SW)_p_value` = ifelse(BP_p_value <= alpha_star3 | SW_p_value <= alpha_star3, 0, 1)) %>%\n  relocate(`Group (BP & SW)_p_value`, .after = `Group (RESET & SW)_p_value`) %>%\n  \n  mutate(`Group (RESET & BP & SW)_p_value` = ifelse(RESET4_p_value <= alpha_star3 | BP_p_value <= alpha_star3 | SW_p_value <= alpha_star3, 0, 1)) %>%\n  relocate(`Group (RESET & BP & SW)_p_value`, .after = `Group (BP & SW)_p_value`)\nconv_pred_group <- conv_test_group_dat %>%\n  select(-RESET3_p_value, -(RESET5_p_value:RESET10_p_value), -F_p_value) %>%\n  rename(RESET_p_value = RESET4_p_value) %>%\n  pivot_longer(RESET_p_value:`Group (RESET & BP & SW)_p_value`) %>%\n  mutate(name = gsub(\"_p_value\", \" test\", name)) %>%\n  mutate(reject = value <= 0.05) %>%\n  select(effect_size, name, reject) %>%\n  mutate(offset0 = log(0.05/0.95)) %>%\n  nest(dat = c(effect_size, offset0, reject)) %>%\n  mutate(mod = map(dat, \n                   ~glm(reject ~ effect_size - 1, \n                        family = binomial(), \n                        data = .x,\n                        offset = offset0))) %>%\n  mutate(power = map(mod, function(mod) {\n    data.frame(effect_size = exp(seq(log(min_es),\n                                     log(max_es),\n                                     0.1)),\n               offset0 = log(0.05/0.95)) %>%\n      mutate(power = predict(mod, type = \"response\", newdata = .))\n  })) %>%\n  select(-dat, -mod) %>%\n  unnest(power) %>%\n  select(-offset0) %>%\n  mutate(log_effect_size = log(effect_size))\nconv_pred_group <- conv_pred_group %>%\n  mutate(name = factor(name, levels = c(\"Group (RESET & BP & SW) test\",\n                                        \"Group (RESET & BP) test\",\n                                        \"Visual test\",\n                                        \"Group (RESET & SW) test\",\n                                        \"Group (BP & SW) test\",\n                                        \"BP test\",\n                                        \"SW test\",\n                                        \"RESET test\")))"},{"path":"combined-tests-reset-bp-and-sw.html","id":"draw-plot-1","chapter":"3 Combined tests (RESET, BP and SW)","heading":"3.2 Draw plot","text":"sensitivity tests ordered follows:Group test (RESET & BP & SW)Group test (RESET & BP)Visual testGroup test (RESET & SW) testGroup test (BP & SW) testBP testSW testRESET test","code":"\nggplot() +\n  geom_point(data = visual_test_dat,\n             aes(log(effect_size), as.numeric(p_value <= 0.05)),\n             alpha = 0.15) +\n  \n  geom_line(data = conv_pred_group,\n            aes(log_effect_size, power, col = name),\n            size = 1) +\n  \n  geom_line(data = visual_boot_pred,\n            aes(log_effect_size, power, col = \"Visual test\", group = boot_id),\n            size = 1,\n            alpha = 0.01) +\n\n  geom_line(data = visual_pred,\n            aes(log_effect_size, power, col = \"Visual test\"),\n            size = 1) +\n  \n  theme_light() +\n  # scale_color_brewer(palette = \"Set3\") +\n  scale_color_manual(breaks = levels(conv_pred_group$name), \n                     values = rev(rcartocolor::carto_pal(8, \"Vivid\"))) +\n  xlab(expression(log[e] (Effect_size))) +\n  ylab(\"Power\") +\n  labs(col = \"\", size = \"# lineups\") +\n  theme(legend.position = \"bottom\")"},{"path":"automatic-visual-inference-system.html","id":"automatic-visual-inference-system","chapter":"4 Automatic Visual Inference System","heading":"4 Automatic Visual Inference System","text":"","code":"\nlibrary(tidyverse)\nlibrary(visage)"},{"path":"automatic-visual-inference-system.html","id":"objectives","chapter":"4 Automatic Visual Inference System","heading":"4.1 Objectives","text":"system’s objective described first second milestone reports evaluate lineups data plots, specifically residual plots, visual tests can conducted without involvement humans.conducting visual test, generally request participant select different plot lineup, cases, select multiple different plots lineup. Automating visual test means system needs ability complete task - select different plot lineup.Within context residual plots, different plot likely one look like good residual plot. may also contain visual patterns indicating model violations. Therefore, measuring different plot good residual plots also potential solution. words, system needs select one looks least like good residual plot. However, can anticipated system work types data plots, bar plots. accomplish task, need general-purpose (sense data plots) image comparison algorithm.","code":""},{"path":"automatic-visual-inference-system.html","id":"model-violations","chapter":"4 Automatic Visual Inference System","heading":"4.2 Model Violations","text":"giving p-values visual tests, system may also detect potential issues residual plots. model violations declared exposed system beforehand.two violations considered paper - non-linearity heteroskedasticity. simulate non-linearity Hermite polynomials simulate heteroskedasticity quadratic variance function. forms non-linearity, inverse exponential functions predictors. Heteroskedasticity also exhibit shapes “triangle” “butterfly”.Non-normality also mentioned paper. violation classical normal linear regression model assumption, important conducting hypothesis testing interval estimation. violation can simulated different commonly assumed distributions, like student’s t-distribution uniform distribution.Autocorrelation another worth-checking model violation. happens errors correlated different time periods. Regression analysis literature recommends use Durbin-Watson test. similar checking lag one sample autocorrelation coefficient. can simulate model violation AR(1) model.model violations commonly checked residual diagnostics. Instead simulating model violation separately, can also simulate mixed model violations, combination non-linearity non-normality.","code":""},{"path":"automatic-visual-inference-system.html","id":"inputs-and-outpus","chapter":"4 Automatic Visual Inference System","heading":"4.3 Inputs and outpus","text":"Grouped different kinds inputs outputs, can design system differently.consider input single residual plot, better aesthetic plot standardised. Users generally access raw residuals fitted values. may provide function help produce residual plot.Input: Single standard residual plot\nOutput: probability plot begin rejected visual test.Input: Single standard residual plot\nOutput: probability plot exhibiting residual departures.Raw-Input: Residuals fitted values\nInput: Single standard residual plot\nOutput: probability plot exhibiting residual departures.mentioned , system may also provide type model violations. can usually done multiclass classifier.Raw-Input: Residuals fitted values\nInput: Single standard residual plot\nOutput: probability plot exhibiting departure (multiclass).Additionally, raw numerical data may used additional information help make accurate predictions.Raw-Input: Residuals fitted values\nInput: Standard residual plot & residuals\nOutput: probability plot exhibiting residual departures.Raw-Input: Residuals fitted values\nInput: Standard residual plot & residuals\nOutput: probability plot exhibiting departure (multiclass).like follow lineup protocol, input system lineup residual plots. can ask system perform task humans, select different plot(s).Input: Multiple residual plots (lineup)\nOutput: different plot.Input: Multiple residual plots (lineup)\nOutput: different plots., unlike humans, computer vision models can possibly produce ranking residual plots lineup. ranking, novel inference method can developed.Input: Multiple residual plots (lineup)\nOutput: Ranking (different plot)","code":""},{"path":"automatic-visual-inference-system.html","id":"data","chapter":"4 Automatic Visual Inference System","heading":"4.4 Data","text":"terms training computer vision model(s) embedded system. need consider data available moment. 8860 lineup evaluations collected experiment. means least thousand images per class (null plot ).need data, cost per observation around 0.25 Australian Dollars. time needs collecting data around 6 minutes per observation.also let model learn characteristics null plots exposing simulated null plots .potential sources data.Pure human dataSimulated data + human dataPure simulated dataIf want model can mimic behaviour humans, direct way train use human data. However, larger training set can formed simulated data also used. Models trained pure simulated data may perform like humans. like conventional test summarizes information residuals. Though may like visual test conducted humans, still valuable.","code":""},{"path":"automatic-visual-inference-system.html","id":"architectures","chapter":"4 Automatic Visual Inference System","heading":"4.5 Architectures","text":"terms model architectures, first need consider availability source code. Due time constraint, possibility need borrow CNN model structures existing model, VGG16 ResNet.different kinds CNN model architectures can considered:Traditional image classifier\nVGG16, VGG19, etc.\nAvailable Keras Applications\nMature APIs\naccepts single image time, want use multiple images input, need design new model.\nVGG16, VGG19, etc.Available Keras ApplicationsMature APIsBut accepts single image time, want use multiple images input, need design new model.Generative adversarial network\nBased idea autoencoders\nReproduce null plots\nDenoise null plots\nreproduced target plot different target plot, likely plot exhibiting residual departures.\nBased idea autoencodersReproduce null plotsDenoise null plotsIf reproduced target plot different target plot, likely plot exhibiting residual departures.","code":""},{"path":"automatic-visual-inference-system.html","id":"concerns","chapter":"4 Automatic Visual Inference System","heading":"4.6 Concerns","text":"sufficient data train model? say generally need >1000 images label.Can model detect residual departures non-linearity heteroskedasticity?\n- depends. model actually learns select different residual plot, chance detecting departures. model learns detect shapes feed, probably able , unless departures share similar characteristics non-linearity heteroskedasticity.Can model detect non-linearity heteroskedasticity shapes design?Can model applied data plots?","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
